{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import local"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if no test dataset:\n",
    "    train,test    =split\n",
    " = Balance(train)\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=50, n_jobs=-1)\n",
    "\n",
    "bagging n boost = True\n",
    "\n",
    "sklearn.calibration.\n",
    "clf_cal = CalibratedClassifierCV(cv_clf,cv=prefit, cv = k)   resulting in k**2\n",
    "\n",
    "2 modes for kaggle\n",
    "1. train,train-valid, train-test using split-train_test\n",
    "    ratio = .2 verify model against train dataset\n",
    "2. train,train-valid, test using split-train_test \n",
    "   create model from bigger trainset, using ratio = 0.2.0,1 etce\n",
    "use clf_cal. predict on test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-06T20:04:11.204254Z",
     "start_time": "2019-08-06T20:04:03.330524Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# packages in environment at /Users/brucecottman/anaconda3/envs/paso:\r\n",
      "#\r\n",
      "# Name                    Version                   Build  Channel\r\n",
      "_ipyw_jlab_nb_ext_conf    0.1.0                    py37_0  \r\n",
      "absl-py                   0.7.0                    pypi_0    pypi\r\n",
      "alabaster                 0.7.12                   py37_0  \r\n",
      "anaconda-client           1.7.2                    py37_0  \r\n",
      "anaconda-navigator        1.9.6                    py37_0  \r\n",
      "anaconda-project          0.8.2                    py37_0  \r\n",
      "ansimarkup                1.4.0                    pypi_0    pypi\r\n",
      "appnope                   0.1.0                    py37_0  \r\n",
      "appscript                 1.0.1            py37h1de35cc_1  \r\n",
      "asn1crypto                0.24.0                   py37_0  \r\n",
      "astor                     0.7.1                    pypi_0    pypi\r\n",
      "astroid                   2.1.0                    py37_0  \r\n",
      "astropy                   3.1              py37h1de35cc_0  \r\n",
      "atomicwrites              1.2.1                    py37_0  \r\n",
      "attrdict                  2.0.1                    pypi_0    pypi\r\n",
      "attrs                     18.2.0           py37h28b3542_0  \r\n",
      "babel                     2.6.0                    py37_0  \r\n",
      "backcall                  0.1.0                    py37_0  \r\n",
      "backports                 1.0                      py37_1  \r\n",
      "backports.os              0.1.1                    py37_0  \r\n",
      "backports.shutil_get_terminal_size 1.0.0                    py37_2  \r\n",
      "beautifulsoup4            4.6.3                    py37_0  \r\n",
      "better-exceptions-fork    0.2.1.post6              pypi_0    pypi\r\n",
      "bitarray                  0.8.3            py37h1de35cc_0  \r\n",
      "bkcharts                  0.2                      py37_0  \r\n",
      "blas                      1.0                         mkl  \r\n",
      "blaze                     0.11.3                   py37_0  \r\n",
      "bleach                    3.0.2                    py37_0  \r\n",
      "blosc                     1.14.4               hd9629dc_0  \r\n",
      "bokeh                     1.0.4                    py37_0  \r\n",
      "boto                      2.49.0                   py37_0  \r\n",
      "boto3                     1.9.148                  pypi_0    pypi\r\n",
      "botocore                  1.12.148                 pypi_0    pypi\r\n",
      "bottleneck                1.2.1            py37h1d22016_1  \r\n",
      "bzip2                     1.0.6                h1de35cc_5  \r\n",
      "ca-certificates           2019.1.23                     0  \r\n",
      "cairo                     1.14.12              hc4e6be7_4  \r\n",
      "catboost                  0.12.2                   pypi_0    pypi\r\n",
      "category-encoders         2.0.0                    pypi_0    pypi\r\n",
      "certifi                   2019.3.9                 py37_0  \r\n",
      "cffi                      1.11.5           py37h6174b99_1  \r\n",
      "chardet                   3.0.4                    py37_1  \r\n",
      "click                     7.0                      py37_0  \r\n",
      "cloudpickle               0.6.1                    py37_0  \r\n",
      "clyent                    1.2.2                    py37_1  \r\n",
      "colorama                  0.4.1                    py37_0  \r\n",
      "conda-verify              3.1.1                    py37_0  \r\n",
      "contextlib2               0.5.5                    py37_0  \r\n",
      "coverage                  4.5.2                    pypi_0    pypi\r\n",
      "cryptography              2.4.2            py37ha12b0ac_0  \r\n",
      "curl                      7.63.0            ha441bb4_1000  \r\n",
      "cvxpy                     1.0.18                   pypi_0    pypi\r\n",
      "cycler                    0.10.0                   py37_0  \r\n",
      "cymem                     2.0.2                    pypi_0    pypi\r\n",
      "cython                    0.29.2           py37h0a44026_0  \r\n",
      "cytoolz                   0.9.0.1          py37h1de35cc_1  \r\n",
      "dask                      1.0.0                    py37_0  \r\n",
      "dask-core                 1.0.0                    py37_0  \r\n",
      "datashape                 0.5.4                    py37_1  \r\n",
      "dbus                      1.13.2               h760590f_1  \r\n",
      "decorator                 4.3.0                    py37_0  \r\n",
      "defusedxml                0.5.0                    py37_1  \r\n",
      "dill                      0.2.9                    pypi_0    pypi\r\n",
      "distributed               1.25.1                   py37_0  \r\n",
      "docutils                  0.14                     py37_0  \r\n",
      "ecos                      2.0.7.post1              pypi_0    pypi\r\n",
      "entrypoints               0.2.3                    py37_2  \r\n",
      "enum34                    1.1.6                    pypi_0    pypi\r\n",
      "et_xmlfile                1.0.1                    py37_0  \r\n",
      "expat                     2.2.6                h0a44026_0  \r\n",
      "fancyimpute               0.4.2                    pypi_0    pypi\r\n",
      "fastai                    1.0.45                   pypi_0    pypi\r\n",
      "fastcache                 1.0.2            py37h1de35cc_2  \r\n",
      "fastprogress              0.1.19                   pypi_0    pypi\r\n",
      "filelock                  3.0.10                   py37_0  \r\n",
      "findspark                 1.3.0                    pypi_0    pypi\r\n",
      "flask                     1.0.2                    py37_1  \r\n",
      "flask-cors                3.0.7                    py37_0  \r\n",
      "flatbuffers               1.10                     pypi_0    pypi\r\n",
      "fontconfig                2.13.0               h5d5b041_1  \r\n",
      "freetype                  2.9.1                hb4e5f40_0  \r\n",
      "fribidi                   1.0.5                h1de35cc_0  \r\n",
      "funcsigs                  1.0.2                    pypi_0    pypi\r\n",
      "future                    0.17.1                   py37_0  \r\n",
      "gast                      0.2.2                    pypi_0    pypi\r\n",
      "get_terminal_size         1.0.0                h7520d66_0  \r\n",
      "gettext                   0.19.8.1             h15daf44_3  \r\n",
      "gevent                    1.3.7            py37h1de35cc_1  \r\n",
      "glib                      2.56.2               hd9629dc_0  \r\n",
      "glob2                     0.6                      py37_1  \r\n",
      "gmp                       6.1.2                hb37e062_1  \r\n",
      "gmpy2                     2.0.8            py37h6ef4df4_2  \r\n",
      "graphite2                 1.3.13               h2098e52_0  \r\n",
      "graphviz                  2.40.1               hefbbd9a_2  \r\n",
      "greenlet                  0.4.15           py37h1de35cc_0  \r\n",
      "grpcio                    1.18.0                   pypi_0    pypi\r",
      "\r\n",
      "h5py                      2.8.0            py37h878fce3_3  \r\n",
      "harfbuzz                  1.8.8                hb8d4a28_0  \r\n",
      "hdf5                      1.10.2               hfa1e0ec_1  \r\n",
      "heapdict                  1.0.0                    py37_2  \r\n",
      "html5lib                  1.0.1                    py37_0  \r\n",
      "icu                       58.2                 h4b95b61_1  \r\n",
      "idna                      2.8                      py37_0  \r\n",
      "imageio                   2.4.1                    py37_0  \r\n",
      "imagesize                 1.1.0                    py37_0  \r\n",
      "imbalanced-learn          0.4.3                    pypi_0    pypi\r\n",
      "importlib_metadata        0.6                      py37_0  \r\n",
      "intel-openmp              2019.1                      144  \r\n",
      "ipykernel                 5.1.0            py37h39e3cac_0  \r\n",
      "ipython                   7.2.0            py37h39e3cac_0  \r\n",
      "ipython_genutils          0.2.0                    py37_0  \r\n",
      "ipywidgets                7.4.2                    py37_0  \r\n",
      "isort                     4.3.4                    py37_0  \r\n",
      "isoweek                   1.3.3                    pypi_0    pypi\r\n",
      "itsdangerous              1.1.0                    py37_0  \r\n",
      "jbig                      2.1                  h4d881f8_0  \r\n",
      "jdcal                     1.4                      py37_0  \r\n",
      "jedi                      0.13.2                   py37_0  \r\n",
      "jinja2                    2.10                     py37_0  \r\n",
      "jmespath                  0.9.4                    pypi_0    pypi\r\n",
      "joblib                    0.13.2                   pypi_0    pypi\r\n",
      "jpeg                      9b                   he5867d9_2  \r\n",
      "jsonschema                2.6.0                    py37_0  \r\n",
      "jupyter                   1.0.0                    py37_7  \r\n",
      "jupyter-contrib-core      0.3.3                    pypi_0    pypi\r\n",
      "jupyter-contrib-nbextensions 0.5.1                    pypi_0    pypi\r\n",
      "jupyter-highlight-selected-word 0.2.0                    pypi_0    pypi\r\n",
      "jupyter-latex-envs        1.4.6                    pypi_0    pypi\r\n",
      "jupyter-nbextensions-configurator 0.4.1                    pypi_0    pypi\r\n",
      "jupyter_client            5.2.4                    py37_0  \r\n",
      "jupyter_console           6.0.0                    py37_0  \r\n",
      "jupyter_core              4.4.0                    py37_0  \r\n",
      "jupyterlab                0.35.3                   py37_0  \r\n",
      "jupyterlab_server         0.2.0                    py37_0  \r\n",
      "keras                     2.2.4                    pypi_0    pypi\r\n",
      "keras-applications        1.0.7                    pypi_0    pypi\r\n",
      "keras-preprocessing       1.0.9                    pypi_0    pypi\r\n",
      "keyring                   17.0.0                   py37_0  \r\n",
      "kiwisolver                1.0.1            py37h0a44026_0  \r\n",
      "knnimpute                 0.1.0                    pypi_0    pypi\r\n",
      "krb5                      1.16.1               hddcf347_7  \r\n",
      "lazy-object-proxy         1.3.1            py37h1de35cc_2  \r\n",
      "libarchive                3.3.3                h786848e_5  \r\n",
      "libcurl                   7.63.0            h051b688_1000  \r\n",
      "libcxx                    4.0.1                hcfea43d_1  \r\n",
      "libcxxabi                 4.0.1                hcfea43d_1  \r\n",
      "libedit                   3.1.20170329         hb402a30_2  \r\n",
      "libffi                    3.2.1                h475c297_4  \r\n",
      "libgfortran               3.0.1                h93005f0_2  \r\n",
      "libiconv                  1.15                 hdd342a3_7  \r\n",
      "liblief                   0.9.0                h2a1bed3_0  \r\n",
      "libpng                    1.6.35               ha441bb4_0  \r\n",
      "libsodium                 1.0.16               h3efe00b_0  \r\n",
      "libssh2                   1.8.0                ha12b0ac_4  \r\n",
      "libtiff                   4.0.9                hcb84e12_2  \r\n",
      "libxml2                   2.9.8                hab757c2_1  \r\n",
      "libxslt                   1.1.32               hb819dd2_0  \r\n",
      "lightgbm                  2.2.3                    pypi_0    pypi\r\n",
      "llvm-openmp               4.0.1                hcfea43d_1  \r\n",
      "llvmlite                  0.26.0           py37h8c7ce04_0  \r\n",
      "locket                    0.2.0                    py37_1  \r\n",
      "loguru                    0.2.5                    pypi_0    pypi\r\n",
      "lxml                      4.2.5            py37hef8c89e_0  \r\n",
      "lz4-c                     1.8.1.2              h1de35cc_0  \r\n",
      "lzo                       2.10                 h362108e_2  \r\n",
      "markdown                  3.0.1                    pypi_0    pypi\r\n",
      "markupsafe                1.1.0            py37h1de35cc_0  \r\n",
      "matplotlib                3.0.2            py37h54f8f79_0  \r\n",
      "mccabe                    0.6.1                    py37_1  \r\n",
      "mistune                   0.8.4            py37h1de35cc_0  \r\n",
      "mkl                       2019.1                      144  \r\n",
      "mkl-service               1.1.2            py37hfbe908c_5  \r\n",
      "mkl_fft                   1.0.6            py37h27c97d8_0  \r\n",
      "mkl_random                1.0.2            py37h27c97d8_0  \r\n",
      "mock                      2.0.0                    pypi_0    pypi\r\n",
      "modin                     0.4.0                    pypi_0    pypi\r\n",
      "more-itertools            4.3.0                    py37_0  \r\n",
      "mpc                       1.1.0                h6ef4df4_1  \r\n",
      "mpfr                      4.0.1                h3018a27_3  \r\n",
      "mpmath                    1.1.0                    py37_0  \r\n",
      "msgpack-numpy             0.4.3.2                  pypi_0    pypi\r\n",
      "msgpack-python            0.5.6            py37h04f5b5a_1  \r\n",
      "multipledispatch          0.6.0                    py37_0  \r\n",
      "multiprocess              0.70.7                   pypi_0    pypi\r\n",
      "murmurhash                1.0.1                    pypi_0    pypi\r\n",
      "navigator-updater         0.2.1                    py37_0  \r\n",
      "nbconvert                 5.4.1                    pypi_0    pypi\r\n",
      "nbformat                  4.4.0                    py37_0  \r\n",
      "nbsphinx                  0.4.2                    pypi_0    pypi\r\n",
      "ncurses                   6.1                  h0a44026_1  \r\n",
      "networkx                  2.2                      py37_1  \r\n",
      "ninja                     1.8.2            py37h04f5b5a_1  \r\n",
      "nltk                      3.4                      py37_1  \r\n",
      "nose                      1.3.7                    py37_2  \r\n",
      "notebook                  5.7.4                    py37_0  \r\n",
      "np-utils                  0.5.9.0                  pypi_0    pypi\r\n",
      "numba                     0.41.0           py37h6440ff4_0  \r\n",
      "numexpr                   2.6.8            py37h7413580_0  \r\n",
      "numpy                     1.15.0                   pypi_0    pypi\r\n",
      "numpydoc                  0.8.0                    py37_0  \r\n",
      "nvidia-ml-py3             7.352.0                  pypi_0    pypi\r\n",
      "odo                       0.5.1                    py37_0  \r\n",
      "olefile                   0.46                     py37_0  \r\n",
      "openpyxl                  2.5.12                   py37_0  \r\n",
      "openssl                   1.1.1b               h1de35cc_1  \r\n",
      "osqp                      0.5.0                    pypi_0    pypi\r\n",
      "packaging                 18.0                     py37_0  \r\n",
      "pandas                    0.24.1                   pypi_0    pypi\r\n",
      "pandas-summary            0.0.6                    pypi_0    pypi\r\n",
      "pandoc                    1.19.2.1             ha5e8f32_1  \r\n",
      "pandocfilters             1.4.2                    py37_1  \r\n",
      "pango                     1.42.4               h060686c_0  \r\n",
      "parso                     0.3.1                    py37_0  \r\n",
      "partd                     0.3.9                    py37_0  \r\n",
      "path.py                   11.5.0                   py37_0  \r\n",
      "pathlib2                  2.3.3                    py37_0  \r\n",
      "patsy                     0.5.1                    py37_0  \r\n",
      "pbr                       5.1.2                    pypi_0    pypi\r\n",
      "pcre                      8.42                 h378b8a2_0  \r\n",
      "pep8                      1.7.1                    py37_0  \r\n",
      "pexpect                   4.6.0                    py37_0  \r\n",
      "pickleshare               0.7.5                    py37_0  \r\n",
      "pillow                    5.3.0            py37hb68e598_0  \r\n",
      "pip                       19.1.1                   pypi_0    pypi\r\n",
      "pixman                    0.38.0               h1de35cc_0  \r\n",
      "pkginfo                   1.4.2                    py37_1  \r\n",
      "plac                      0.9.6                    pypi_0    pypi\r\n",
      "plotly                    3.6.1                    pypi_0    pypi\r\n",
      "pluggy                    0.8.0                    py37_0  \r\n",
      "ply                       3.11                     py37_0  \r\n",
      "preshed                   2.0.1                    pypi_0    pypi\r\n",
      "probscale                 0.2.3                    pypi_0    pypi\r\n",
      "prometheus_client         0.5.0                    py37_0  \r\n",
      "prompt_toolkit            2.0.7                    py37_0  \r\n",
      "protobuf                  3.6.1                    pypi_0    pypi\r\n",
      "psutil                    5.4.8            py37h1de35cc_0  \r\n",
      "ptyprocess                0.6.0                    py37_0  \r\n",
      "py                        1.7.0                    py37_0  \r\n",
      "py-lief                   0.9.0            py37hd4eaf27_0  \r\n",
      "py4j                      0.10.7                   pypi_0    pypi\r\n",
      "pyarrow                   0.12.0                   pypi_0    pypi\r\n",
      "pycodestyle               2.4.0                    py37_0  \r\n",
      "pycosat                   0.6.3            py37h1de35cc_0  \r\n",
      "pycparser                 2.19                     py37_0  \r\n",
      "pycrypto                  2.6.1            py37h1de35cc_9  \r\n",
      "pycurl                    7.43.0.2         py37ha12b0ac_0  \r\n",
      "pydataset                 0.2.0                    pypi_0    pypi\r\n",
      "pydot                     1.3.0                    py37_1  \r\n",
      "pydot-ng                  2.0.0                    pypi_0    pypi\r\n",
      "pyflakes                  2.0.0                    py37_0  \r\n",
      "pygments                  2.3.1                    py37_0  \r\n",
      "pylint                    2.2.2                    py37_0  \r\n",
      "pyodbc                    4.0.25           py37h0a44026_0  \r\n",
      "pyopenssl                 18.0.0                   py37_0  \r\n",
      "pyparsing                 2.3.0                    py37_0  \r\n",
      "pyqt                      5.9.2            py37h655552a_2  \r\n",
      "pysocks                   1.6.8                    py37_0  \r\n",
      "pyspark                   2.4.3                    pypi_0    pypi\r\n",
      "pytables                  3.4.4            py37h13cba08_0  \r\n",
      "pytest                    4.0.2                    py37_0  \r\n",
      "pytest-arraydiff          0.3              py37h39e3cac_0  \r\n",
      "pytest-astropy            0.5.0                    py37_0  \r\n",
      "pytest-doctestplus        0.2.0                    py37_0  \r\n",
      "pytest-openfiles          0.3.1                    py37_0  \r\n",
      "pytest-remotedata         0.3.1                    py37_0  \r\n",
      "python                    3.7.1                haf84260_7  \r\n",
      "python-dateutil           2.7.5                    py37_0  \r\n",
      "python-libarchive-c       2.8                      py37_6  \r\n",
      "python.app                2                        py37_9  \r\n",
      "pytorch                   1.0.1                   py3.7_2    pytorch\r\n",
      "pytz                      2018.7                   py37_0  \r\n",
      "pywavelets                1.0.1            py37h1d22016_0  \r\n",
      "pyyaml                    3.13             py37h1de35cc_0  \r\n",
      "pyzmq                     17.1.2           py37h1de35cc_0  \r\n",
      "qt                        5.9.7                h468cd18_1  \r\n",
      "qtawesome                 0.5.3                    py37_0  \r\n",
      "qtconsole                 4.4.3                    py37_0  \r\n",
      "qtpy                      1.5.2                    py37_0  \r\n",
      "ray                       0.6.2                    pypi_0    pypi\r\n",
      "readline                  7.0                  h1de35cc_5  \r\n",
      "redis                     3.2.1                    pypi_0    pypi\r\n",
      "regex                     2018.1.10                pypi_0    pypi\r\n",
      "requests                  2.21.0                   py37_0  \r\n",
      "retrying                  1.3.3                    pypi_0    pypi\r\n",
      "rope                      0.11.0                   py37_0  \r\n",
      "ruamel_yaml               0.15.46          py37h1de35cc_0  \r\n",
      "s3fs                      0.2.1                    pypi_0    pypi\r\n",
      "s3transfer                0.2.0                    pypi_0    pypi\r\n",
      "scikit-image              0.14.1           py37h0a44026_0  \r\n",
      "scikit-learn              0.20.1           py37h27c97d8_0  \r\n",
      "scipy                     1.1.0            py37h1410ff5_2  \r\n",
      "scs                       2.0.2                    pypi_0    pypi\r\n",
      "seaborn                   0.9.0                    py37_0  \r\n",
      "send2trash                1.5.0                    py37_0  \r\n",
      "setuptools                40.6.3                   py37_0  \r\n",
      "simplegeneric             0.8.1                    py37_2  \r\n",
      "singledispatch            3.4.0.3                  py37_0  \r\n",
      "sip                       4.19.8           py37h0a44026_0  \r\n",
      "six                       1.12.0                   py37_0  \r\n",
      "sklearn                   0.0                      pypi_0    pypi\r\n",
      "sklearn-pandas            1.8.0                    pypi_0    pypi\r\n",
      "snappy                    1.1.7                he62c110_3  \r\n",
      "snowballstemmer           1.2.1                    py37_0  \r\n",
      "sortedcollections         1.0.1                    py37_0  \r\n",
      "sortedcontainers          2.1.0                    py37_0  \r\n",
      "spacy                     2.0.18                   pypi_0    pypi\r\n",
      "sphinx                    1.8.2                    py37_0  \r\n",
      "sphinx-automodapi         0.10                     pypi_0    pypi\r\n",
      "sphinx-gallery            0.2.0                    pypi_0    pypi\r\n",
      "sphinx-rtd-theme          0.4.3                    pypi_0    pypi\r\n",
      "sphinxcontrib             1.0                      py37_1  \r\n",
      "sphinxcontrib-websupport  1.1.0                    py37_1  \r\n",
      "spyder                    3.3.2                    py37_0  \r\n",
      "spyder-kernels            0.3.0                    py37_0  \r\n",
      "sqlalchemy                1.2.15           py37h1de35cc_0  \r\n",
      "sqlite                    3.26.0               ha441bb4_0  \r\n",
      "statsmodels               0.9.0            py37h1d22016_0  \r\n",
      "sympy                     1.3                      py37_0  \r\n",
      "tblib                     1.3.2                    py37_0  \r\n",
      "tensorboard               1.12.2                   pypi_0    pypi\r\n",
      "tensorflow                1.13.0rc2                pypi_0    pypi\r\n",
      "tensorflow-estimator      1.13.0rc0                pypi_0    pypi\r\n",
      "termcolor                 1.1.0                    pypi_0    pypi\r\n",
      "terminado                 0.8.1                    py37_1  \r\n",
      "testpath                  0.4.2                    py37_0  \r\n",
      "thinc                     6.12.1                   pypi_0    pypi\r\n",
      "tk                        8.6.8                ha441bb4_0  \r\n",
      "toolz                     0.9.0                    py37_0  \r\n",
      "torchvision               0.2.1                      py_2    pytorch\r\n",
      "tornado                   5.1.1            py37h1de35cc_0  \r\n",
      "tqdm                      4.28.1           py37h28b3542_0  \r\n",
      "traitlets                 4.3.2                    py37_0  \r\n",
      "typing                    3.6.6                    pypi_0    pypi\r\n",
      "ujson                     1.35                     pypi_0    pypi\r\n",
      "unicodecsv                0.14.1                   py37_0  \r\n",
      "unixodbc                  2.3.7                h1de35cc_0  \r\n",
      "urllib3                   1.24.1                   py37_0  \r\n",
      "wand                      0.5.1                    pypi_0    pypi\r\n",
      "wcwidth                   0.1.7                    py37_0  \r\n",
      "webencodings              0.5.1                    py37_1  \r\n",
      "werkzeug                  0.14.1                   py37_0  \r\n",
      "wheel                     0.32.3                   py37_0  \r\n",
      "widgetsnbextension        3.4.2                    py37_0  \r\n",
      "wrapt                     1.10.11          py37h1de35cc_2  \r\n",
      "wurlitzer                 1.0.2                    py37_0  \r\n",
      "xgboost                   0.81                     pypi_0    pypi\r\n",
      "xlrd                      1.2.0                    py37_0  \r\n",
      "xlsxwriter                1.1.2                    py37_0  \r\n",
      "xlwings                   0.15.1                   py37_0  \r\n",
      "xlwt                      1.3.0                    py37_0  \r\n",
      "xz                        5.2.4                h1de35cc_4  \r\n",
      "yaml                      0.1.7                hc338f04_2  \r\n",
      "zeromq                    4.2.5                h0a44026_1  \r\n",
      "zict                      0.1.3                    py37_0  \r\n",
      "zlib                      1.2.11               h1de35cc_3  \r\n",
      "zstd                      1.3.7                h5bba6e5_0  \r\n"
     ]
    }
   ],
   "source": [
    "!conda list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-06T20:04:11.647893Z",
     "start_time": "2019-08-06T20:04:11.330033Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/brucecottman/Documents/PROJECTS/paso'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "__file__ = !cd .. ;pwd\n",
    "__file__ = __file__[0]\n",
    "__file__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-06T20:04:12.736401Z",
     "start_time": "2019-08-06T20:04:11.789646Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/brucecottman/Documents/PROJECTS/paso/lessons',\n",
       " '/Users/brucecottman/anaconda3/envs/paso/lib/python37.zip',\n",
       " '/Users/brucecottman/anaconda3/envs/paso/lib/python3.7',\n",
       " '/Users/brucecottman/anaconda3/envs/paso/lib/python3.7/lib-dynload',\n",
       " '',\n",
       " '/Users/brucecottman/.local/lib/python3.7/site-packages',\n",
       " '/Users/brucecottman/anaconda3/envs/paso/lib/python3.7/site-packages',\n",
       " '/Users/brucecottman/anaconda3/envs/paso/lib/python3.7/site-packages/aeosa',\n",
       " '/Users/brucecottman/anaconda3/envs/paso/lib/python3.7/site-packages/IPython/extensions',\n",
       " '/Users/brucecottman/.ipython',\n",
       " '/Users/brucecottman/Documents/PROJECTS/paso']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "from random import random\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "sys.path.append(__file__)\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-06T20:04:15.109093Z",
     "start_time": "2019-08-06T20:04:12.853117Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paso 6.8.2019 16:04:14 INFO Log started\n",
      "paso 6.8.2019 16:04:14 INFO ========================================\n",
      "paso 6.8.2019 16:04:14 INFO Read in parameter file: ../parameters/lesson.3.yaml\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas_summary import DataFrameSummary\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import multiprocessing\n",
    "\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import cm\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "color = sns.color_palette()\n",
    "sns.set(rc={'figure.figsize':(6,4)})\n",
    "from paso.base import Paso,Log,PasoError\n",
    "from loguru import logger\n",
    "session = Paso(parameters_filepath='../parameters/lesson.3.yaml').startup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-06T20:04:15.630577Z",
     "start_time": "2019-08-06T20:04:15.231391Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paso 6.8.2019 16:04:15 INFO ========================================\n",
      "paso 6.8.2019 16:04:15 INFO Read in parameter file: ../parameters/lesson.3.yaml\n"
     ]
    }
   ],
   "source": [
    "from paso.base import Paso,Log,PasoError,Param,NameToClass\n",
    "from loguru import logger\n",
    "session = Paso(parameters_filepath='../parameters/lesson.3.yaml').startup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balancing and  Augmentating Class Stratified Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Structured Data Augmentation is very rarely discussed in theoretical or real-world production systems. It a secret sauce for which the recipe will be shown here. Along the way, we will introduce ``paso's`` Class Balancing tools. As was shown in the previous two articles, **paso** supports and is compatiable with ``sklearn``.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## A Quick Overview of paso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**paso** is a package written in Python and some ``C``(for speed) that was originally intended to bundle best-practices and state-of-the-art services, classes and functions for the Machine Learning and Deep Learning community. **paso** has grown beyond this to offer patterns, classes and methods you can use in your **Scikit-Learn pipelines** or custom code with or without adopting the entire **paso** package.\n",
    "\n",
    "**Scikit-Learn pipelines** are composed of steps, each step has to be **Scikit-Learn transformer** or a custom **Scikit-Learn transformer**. The last of the pipeline can be a transformer or an estimator, where a **Scikit-Learn estimator** is a compatible model. \n",
    "\n",
    "**paso** has quite a few Class Balancing transformers that are custom **Scikit-Learn transformers**. Note that **paso** translates from Spanish to English to the word step.\n",
    "\n",
    "Discussion will be divided into the following major segments:\n",
    "- Loading a Toy Dataset with **paso** ``Inputer``.\n",
    "- What Class Balancing stratagems are in **paso**.\n",
    "- How to use Class Balancing to argument Fixed Structure data\n",
    "- The benefits of argumenting Fixed Structure data.\n",
    "- As usual the source code for all examples is available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "As we saw in [lesson-1](), we need to startup **paso** services."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-08-06T20:04:03.487Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paso 6.8.2019 16:04:16 INFO ========================================\n",
      "paso 6.8.2019 16:04:16 INFO Read in parameter file: ../parameters/lesson.3.yaml\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas_summary import DataFrameSummary\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import multiprocessing\n",
    "\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import cm\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "color = sns.color_palette()\n",
    "\n",
    "from paso.base import Paso,Log,PasoError\n",
    "from loguru import logger\n",
    "session = Paso(parameters_filepath='../parameters/lesson.3.yaml').startup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Toy Example Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **paso** class is a general method to read in datasets and return them as dataframes. For now, we can use them. In a future lesson we will cover  ``Inputer`` in  detail.  All available ``Inputer`` methods are shown with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-08-06T20:04:03.498Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['exec', 'cvs', 'xls', 'xlsm', 'text', 'image2D', 'image3D']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from paso.pre.inputers import Inputer,Splitter\n",
    "inputer = Inputer(ontological_filepath='../ontologies/pre/inputers/iris.yaml')\n",
    "inputer.inputers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-08-06T20:04:03.578Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paso 6.8.2019 16:04:17 INFO Loaded Ontological file:../ontologies/pre/inputers/iris.yaml \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['train']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputer.datasets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us start with a toy dataset to class balance. we load the ``iris``data set, into the ``flower`` dataframe.  The feature ``TypeOf`` will contain the class target values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-08-06T20:04:03.592Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paso 6.8.2019 16:04:17 INFO Loaded Ontological file:../ontologies/pre/inputers/iris.yaml \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'TypeOf'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flower = inputer.transform()\n",
    "inputer.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A short aside on ontological files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of using keyword arguments cemented in code, I will use an ontological file. One working definition of ontological (from Wikipedia) is:\n",
    "\n",
    "    \"showing the relations between the concepts and categories in a subject area or domain\".\n",
    "\n",
    "We are using ontological files because:\n",
    "- the description of an object (dataset, model,etc.) can be changed without changing code\n",
    "- the parsing performance of an ontological file and python are about the same as both use dynamic typing. This probably would not be case for statically typed language. However, an object's metadata parsing compute is very tiny compared to the action(s) performed on or by the object in all cases encountered so far.  \n",
    "\n",
    "We will found out if ontological files have a measurable overhead as we port **paso** to other frameworks (such as **RAPIDS**) or statically-typed languages (such as ``swift``). At much of python's workhorse packages are in fast, statically-typed ``C``, so I doubt it.\n",
    "\n",
    "Ontological files consist of hierarchy of key-value pairs.  In a future lesson we will cover Ontological files in  detail. [Different Ontological files can be viewed here.](https://github.com/bcottman/paso/tree/master/ontologies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-08-06T20:04:03.599Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>TypeOf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.84333</td>\n",
       "      <td>3.05733</td>\n",
       "      <td>3.758</td>\n",
       "      <td>1.19933</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.828066</td>\n",
       "      <td>0.435866</td>\n",
       "      <td>1.7653</td>\n",
       "      <td>0.762238</td>\n",
       "      <td>0.819232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.8</td>\n",
       "      <td>3</td>\n",
       "      <td>4.35</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.4</td>\n",
       "      <td>3.3</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.9</td>\n",
       "      <td>4.4</td>\n",
       "      <td>6.9</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>counts</th>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uniques</th>\n",
       "      <td>35</td>\n",
       "      <td>23</td>\n",
       "      <td>43</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>missing</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>missing_perc</th>\n",
       "      <td>0%</td>\n",
       "      <td>0%</td>\n",
       "      <td>0%</td>\n",
       "      <td>0%</td>\n",
       "      <td>0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>types</th>\n",
       "      <td>numeric</td>\n",
       "      <td>numeric</td>\n",
       "      <td>numeric</td>\n",
       "      <td>numeric</td>\n",
       "      <td>numeric</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             sepal length (cm) sepal width (cm) petal length (cm)  \\\n",
       "count                      150              150               150   \n",
       "mean                   5.84333          3.05733             3.758   \n",
       "std                   0.828066         0.435866            1.7653   \n",
       "min                        4.3                2                 1   \n",
       "25%                        5.1              2.8               1.6   \n",
       "50%                        5.8                3              4.35   \n",
       "75%                        6.4              3.3               5.1   \n",
       "max                        7.9              4.4               6.9   \n",
       "counts                     150              150               150   \n",
       "uniques                     35               23                43   \n",
       "missing                      0                0                 0   \n",
       "missing_perc                0%               0%                0%   \n",
       "types                  numeric          numeric           numeric   \n",
       "\n",
       "             petal width (cm)    TypeOf  \n",
       "count                     150       150  \n",
       "mean                  1.19933         1  \n",
       "std                  0.762238  0.819232  \n",
       "min                       0.1         0  \n",
       "25%                       0.3         0  \n",
       "50%                       1.3         1  \n",
       "75%                       1.8         2  \n",
       "max                       2.5         2  \n",
       "counts                    150       150  \n",
       "uniques                    22         3  \n",
       "missing                     0         0  \n",
       "missing_perc               0%        0%  \n",
       "types                 numeric   numeric  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DataFrameSummary(flower).summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## It is important to split first before balancing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before training the learner it is very important to balance only the dataset we will train on. We want to know the effect of balancing data on the learner, while not corrupting our validation  dataset with augmented  data that balances the classes.\n",
    "\n",
    "Validation is drawn from the initial train dataset in the hopes it is a sample of the past and future data that the test dataset will be drawn from. The other case where train, valid, test are sampled from the original dataset is covered by splitting the initial dataset to result in train and valid. Then split on train again to get train and test. The order does not matter so long as the second split is also on the train dataset ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-08-06T20:04:03.606Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paso 6.8.2019 16:04:19 INFO Loaded Ontological file:../ontologies/pre/inputers/split-stratify-shuffle-30.yaml \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>TypeOf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>6.7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>4.5</td>\n",
       "      <td>1.7</td>\n",
       "      <td>4.9</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     petal length (cm)  petal width (cm)  sepal length (cm)  sepal width (cm)  \\\n",
       "122                6.7               2.0                7.7               2.8   \n",
       "106                4.5               1.7                4.9               2.5   \n",
       "35                 1.2               0.2                5.0               3.2   \n",
       "40                 1.3               0.3                5.0               3.5   \n",
       "25                 1.6               0.2                5.0               3.0   \n",
       "\n",
       "     TypeOf  \n",
       "122       2  \n",
       "106       2  \n",
       "35        0  \n",
       "40        0  \n",
       "25        0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splitter = Splitter(ontological_filepath='../ontologies/pre/inputers/split-stratify-shuffle-30.yaml')\n",
    "train,test=splitter.transform(flower,target=inputer.target,random_state=11)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The argument ratio is the amount of the dataset to assign to the validation (test) dataset. In this case,\n",
    "``X``and ``y`` datasets into training set(50\\%) and test set(50\\%). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: A ``valid`` dataset is not made as we are not tuning learner parameters in this lesson. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## paso Class for Handling Imbalanced Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All available class balance strategies are shown with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-08-06T20:04:03.624Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RanZOverSample',\n",
       " 'SMOTE',\n",
       " 'ADASYN',\n",
       " 'BorderLineSMOTE',\n",
       " 'SVMSMOTE',\n",
       " 'SMOTENC',\n",
       " 'RandomUnderSample',\n",
       " 'ClusterCentroids',\n",
       " 'NearMiss',\n",
       " 'EditedNearestNeighbour',\n",
       " 'RepeatedEditedNearestNeighbours',\n",
       " 'CondensedNearestNeighbour',\n",
       " 'OneSidedSelection']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from paso.pre.cleaners import Class_Balance\n",
    "class_balancer = Class_Balance(ontological_filepath='../ontologies/cleaners/SMOTE.yaml')\n",
    "class_balancer.classBalancers()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-25T20:11:00.840933Z",
     "start_time": "2019-07-25T20:11:00.787237Z"
    }
   },
   "source": [
    "I am going to oversample the minority classes by using ``SMOOT``. I reccomend [Handling imbalanced datasets in machine learning](https://towardsdatascience.com/handling-imbalanced-datasets-in-machine-learning-7a0e84220f28) for more detail on how to balance class imbalanced datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-08-06T20:04:03.627Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paso 6.8.2019 16:04:20 INFO Loaded Ontological file:../ontologies/pre/cleaners/SMOTE.yaml \n",
      "paso 6.8.2019 16:04:20 INFO Class_Balance:: SMOTE\n",
      "paso 6.8.2019 16:04:20 INFO Class_Balance: SMOTE with kwargs {}\n"
     ]
    }
   ],
   "source": [
    "targetFeature = inputer.target\n",
    "class_balancer = Class_Balance(ontological_filepath='../ontologies/pre/cleaners/SMOTE.yaml')\n",
    "train = class_balancer.transform(train,targetFeature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-08-06T20:04:03.706Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>TypeOf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>123</td>\n",
       "      <td>123</td>\n",
       "      <td>123</td>\n",
       "      <td>123</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.74567</td>\n",
       "      <td>1.20057</td>\n",
       "      <td>5.8294</td>\n",
       "      <td>3.06843</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.72814</td>\n",
       "      <td>0.764709</td>\n",
       "      <td>0.766345</td>\n",
       "      <td>0.432549</td>\n",
       "      <td>0.819836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4.3</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.6</td>\n",
       "      <td>0.3</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.4</td>\n",
       "      <td>1.3</td>\n",
       "      <td>5.8</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>6.3</td>\n",
       "      <td>3.35</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.7</td>\n",
       "      <td>2.5</td>\n",
       "      <td>7.7</td>\n",
       "      <td>4.2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>counts</th>\n",
       "      <td>123</td>\n",
       "      <td>123</td>\n",
       "      <td>123</td>\n",
       "      <td>123</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uniques</th>\n",
       "      <td>44</td>\n",
       "      <td>32</td>\n",
       "      <td>42</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>missing</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>missing_perc</th>\n",
       "      <td>0%</td>\n",
       "      <td>0%</td>\n",
       "      <td>0%</td>\n",
       "      <td>0%</td>\n",
       "      <td>0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>types</th>\n",
       "      <td>numeric</td>\n",
       "      <td>numeric</td>\n",
       "      <td>numeric</td>\n",
       "      <td>numeric</td>\n",
       "      <td>numeric</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             petal length (cm) petal width (cm) sepal length (cm)  \\\n",
       "count                      123              123               123   \n",
       "mean                   3.74567          1.20057            5.8294   \n",
       "std                    1.72814         0.764709          0.766345   \n",
       "min                        1.1              0.1               4.3   \n",
       "25%                        1.6              0.3               5.2   \n",
       "50%                        4.4              1.3               5.8   \n",
       "75%                        5.1              1.8               6.3   \n",
       "max                        6.7              2.5               7.7   \n",
       "counts                     123              123               123   \n",
       "uniques                     44               32                42   \n",
       "missing                      0                0                 0   \n",
       "missing_perc                0%               0%                0%   \n",
       "types                  numeric          numeric           numeric   \n",
       "\n",
       "             sepal width (cm)    TypeOf  \n",
       "count                     123       123  \n",
       "mean                  3.06843         1  \n",
       "std                  0.432549  0.819836  \n",
       "min                       2.2         0  \n",
       "25%                       2.8         0  \n",
       "50%                         3         1  \n",
       "75%                      3.35         2  \n",
       "max                       4.2         2  \n",
       "counts                    123       123  \n",
       "uniques                    32         3  \n",
       "missing                     0         0  \n",
       "missing_perc               0%        0%  \n",
       "types                 numeric   numeric  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DataFrameSummary(train).summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``Class_Balance`` did not change the ``Flower-train`` dataframe as the ``iris``dataset comes class balanced. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-08-06T20:04:03.709Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fd63097c9e8>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set(rc={'figure.figsize':(6,4)})\n",
    "sns.distplot((train[inputer.target].astype('category').cat.codes.astype('int')+1),kde=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## A short aside on cross-validation and classification train/predict model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "In an future lesson, I will cover in detail how to use **paso**'s cross-validation for learners that can train and then predict. In the meantime, you can find a good [overview of cross-validation](https://towardsdatascience.com/train-test-split-and-cross-validation-in-python-80b61beca4b6) and a [detailed discussion of cross-validation](https://scikit-learn.org/stable/modules/cross_validation.html#computing-cross-validated-metrics).\n",
    "\n",
    "In this lesson, we use **repeated random sub-sampling** or ``sklearn.ensemble.BaggingClassifier``. This is hopefully a good choice for the class stratified datasets we will be using.\n",
    "\n",
    "Similar to **K-Fold cross-validation** , we set a value for ``n_estimators`` which signifies the number of times we will train our learner on a random subset of the train dataset. However, in this case ``n_estimator``  will not represent the number of learners.\n",
    "Instead, on each training iteration, we randomly select data points for the train folds. The number of data points we select will be a certain percentage we set for the initial trainng set. For example, if we select ``max_samples= 0.90``, then each iteration we will apply the learner to randomly selected 90% of the data points of our original train dataset.  This is similar to ``K-fold`` with ``K=10``, except the samples in folds are chosen at random and it will be more computational expensive if  ``n_estimator >> K``.\n",
    "\n",
    " You should note that ``BaggingClassifier`` will need keep ``n_estimators`` dataset+tree around. If you have a large dataset, it maybe required to pare the dataset down by removing the weakest predictive features in the initial cleaning. I should have done this with the **otto-group**, but I did not. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the RandomForest learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-08-06T20:04:03.776Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paso 6.8.2019 16:04:23 INFO Loaded Ontological file:../ontologies/learners/RandomForestClassification.yaml \n",
      "paso 6.8.2019 16:04:23 INFO learner: RandomForest with kwargs {'n_estimators': 200, 'n_jobs': -1, 'criterion': 'gini'}\n",
      "paso 6.8.2019 16:04:23 INFO cross_validation: BaggingClassifier\n",
      "paso 6.8.2019 16:04:23 INFO     cv kwargs: {'n_estimators': 100, 'bootstrap_features': True, 'max_samples': 0.9, 'max_features': 1.0, 'n_jobs': -1}\n",
      "paso 6.8.2019 16:17:47 INFO cross_validation: CalibratedClassifierCV\n",
      "paso 6.8.2019 16:17:47 INFO     cv kwargs: {'method': 'isotonic', 'cv': 10}\n"
     ]
    }
   ],
   "source": [
    "from paso.learners.learners import Learner\n",
    "learner = Learner(ontological_filepath='../ontologies/learners/RandomForestClassification.yaml',target='TypeOf')\n",
    "learner.train(train,target=inputer.target\n",
    "              ,checkpoint='irisRandomForest1.ckp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the population of each of the Iris classes is about the same, the accuracy and the F1-score are almost equal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-08-06T20:04:03.803Z"
    }
   },
   "outputs": [],
   "source": [
    "learner.predict(test,measure=True)\n",
    "learner.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-08-06T20:04:03.970Z"
    }
   },
   "outputs": [],
   "source": [
    "learner.wrong_predicted_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, very good scores using ``RandomForestClassifier`` on 70% of dataset train and 30% for of dataset for validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting there were correct class assignments but logloss got slightly worse when we balanced the classes using ``SMOTE``."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using splitter, we can shuffle rows around and get different ``flower`` train and test datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augment the ``iris``dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can augment (increase by 10\\% the amount data) with  synthetic data generated by a claas imbalence scheme,  ``SMOOT``. Just ``TypeOf=0`` needs 15(10%) rows (3 classes of 5 rows) of synthetic data to balance the classes. The result is similar to image augmention in that we accomplished structured data augmentation by increasing the row count ``Isis``dataset with synthetic data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-08-06T20:04:03.988Z"
    }
   },
   "outputs": [],
   "source": [
    "from paso.pre.cleaners import Augment_by_Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-08-06T20:04:03.991Z"
    }
   },
   "outputs": [],
   "source": [
    "from paso.pre.cleaners import Augment_by_Class\n",
    "augmenter = Augment_by_Class(ontological_filepath='../ontologies/pre/cleaners/SMOTE.yaml')\n",
    "ratio = 0.5\n",
    "targetFeature =  inputer.target\n",
    "augment =augmenter.transform(train,targetFeature,ratio)\n",
    "DataFrameSummary(augment).summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the ``mean``, ``std`` and other statistics have slightly changed. Also, the count has inreased by 10% or augmented a structured dataset by 10%. Why do expect slight and not large change in the dataset statistics?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-08-06T20:04:03.994Z"
    }
   },
   "outputs": [],
   "source": [
    "learner.train(augment,target=inputer.target)\n",
    "learner.predict(test,measure=True)\n",
    "learner.metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-01T21:10:09.297466Z",
     "start_time": "2019-07-01T21:09:40.152Z"
    }
   },
   "source": [
    "Hmmm, seemed to improve scores a little bit. Let us try 100% augmentation or double the number of rows in the  ``Flower`` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-08-06T20:04:03.997Z"
    }
   },
   "outputs": [],
   "source": [
    "learner.wrong_predicted_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmentation ``flower`` train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-08-06T20:04:03.999Z"
    }
   },
   "outputs": [],
   "source": [
    "def grinder(N,M,S,input_file):\n",
    "    score = np.zeros((S,N,M+2), dtype=np.float32)\n",
    "    scores = {}\n",
    "    score_names = {0:'logloss'\n",
    "                  ,1:'f1'}\n",
    "    ratio = 1.0\n",
    "\n",
    "    for i in tqdm(range(N)):\n",
    "        inputer = Inputer(ontological_filepath=input_file)\n",
    "        flower = inputer.transform(verbose=False)\n",
    "        splitter = Splitter(ontological_filepath='../ontologies/pre/inputers/split-stratify-shuffle-30.yaml')\n",
    "        train,test=splitter.transform(flower,verbose=False\n",
    "                                      ,target=inputer.target\n",
    "                                      ,random_state=22*(i+1))\n",
    "        # do not balancee       \n",
    "        learner = Learner(ontological_filepath='../ontologies/learners/RandomForestClassification.yaml',target='TypeOf')\n",
    "        learner.train(train,target=inputer.target,verbose=False\n",
    "                      ,checkpoint='irisRandomForest2.ckp')  \n",
    "        learner.predict(test,measure=True)\n",
    "        score[0,i,0] = learner.metrics[score_names[0]]\n",
    "        score[1,i,0] = learner.metrics[score_names[1]]\n",
    "        #Class_Balance\n",
    "        class_balancer = Class_Balance(ontological_filepath='../ontologies/pre/cleaners/SMOTE.yaml')\n",
    "        train = class_balancer.transform(train,inputer.target,verbose=False)\n",
    "        learner = Learner(ontological_filepath='../ontologies/learners/RandomForestClassification.yaml',target='TypeOf')\n",
    "        learner.train(train,target=inputer.target,verbose=False\n",
    "                      ,checkpoint='irisRandomForest2.ckp')\n",
    "        learner.predict(test,measure=True)\n",
    "        score[0,i,1] = learner.metrics[score_names[0]]\n",
    "        score[1,i,1] = learner.metrics[score_names[1]]\n",
    "        #augment\n",
    "        augment = train\n",
    "        for j in range(M):\n",
    "        # 2*1 augmentation\n",
    "            augmenter = Augment_by_Class(ontological_filepath='../ontologies/pre/cleaners/SMOTE.yaml')\n",
    "            ratio = 1.0\n",
    "            targetFeature =  inputer.target\n",
    "            augment =augmenter.transform(augment,inputer.target,ratio,verbose=False)\n",
    "            learner = Learner(ontological_filepath='../ontologies/learners/RandomForestClassification.yaml',target='TypeOf')\n",
    "            learner.train(augment,target=inputer.target,verbose=False\n",
    "                          ,checkpoint='irisRandomForest2.ckp')\n",
    "            learner.predict(test,measure=True)\n",
    "            score[0,i,j+2] = learner.metrics[score_names[0]]\n",
    "            score[1,i,j+2] = learner.metrics[score_names[1]]\n",
    "        learner.wrong_predicted_class\n",
    "    scores[score_names[0]] = score[0,:,:]\n",
    "    scores[score_names[1]] = score[1,:,:]\n",
    "    return score_names,scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-08-06T20:04:04.001Z"
    }
   },
   "outputs": [],
   "source": [
    "N = 10  #trial\n",
    "M = 4 # augmentation 2**M\n",
    "S= 2 #scores to keep\n",
    "score_names,scores = grinder(N,M,S,'../ontologies/pre/inputers/iris.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-08-06T20:04:04.098Z"
    }
   },
   "outputs": [],
   "source": [
    "baseline = scores[score_names[0]][:,0]\n",
    "aug_mean = np.mean(scores[score_names[0]][:,1:],axis=1)\n",
    "score_names[0],baseline,aug_mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-08-06T20:04:04.101Z"
    }
   },
   "outputs": [],
   "source": [
    "np.mean(baseline/aug_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-08-06T20:04:04.103Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(x=a ,y=baseline/aug_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-08-06T20:04:04.116Z"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn\n",
    "for i in range(N):\n",
    "    grid = seaborn.lineplot(x=range(M+2) ,y=scores[score_names[0]][i,:])\n",
    "    grid.set(xscale=\"linear\", yscale=\"log\")\n",
    "plt.show()\n",
    "for i in range(N):\n",
    "    grid = seaborn.lineplot(x=range(M+2) ,y=scores[score_names[1]][i,:])\n",
    "    grid.set(xscale=\"linear\", yscale=\"log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-29T20:04:22.014608Z",
     "start_time": "2019-06-29T20:04:21.962258Z"
    }
   },
   "source": [
    "It seems to be more worse on logloss but same on other metrics relating to class assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-29T19:47:04.003749Z",
     "start_time": "2019-07-29T19:47:03.951521Z"
    }
   },
   "source": [
    "Worse on logloss and the same on accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the third time in a row always the same 2 datapoints. It seems no matter how much we augment these two can not predicted in the right class.  I wondr if they are mis-labeled.  If we take them out, then train will predict test 100% accuracy. Hmm!, I wonder what logloss score would be?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seemed to lower the logloss more which means the learner is better at assigning correct class probabilities. Note,isotonic in ``CalibratedClassifierCV`` is similar to clipping both ends of predicted class probability distributions. Let us augment the train dataset again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still causing logloss to go down. Let us stop there on this toy dataset and see how we do on a larger and noisier dataset. \n",
    "\n",
    "Now we cleanup all the object instances we made and no longer need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-08-06T20:04:04.120Z"
    }
   },
   "outputs": [],
   "source": [
    "del inputer\n",
    "del splitter\n",
    "del class_balancer\n",
    "del augmenter\n",
    "del learner\n",
    "del flower\n",
    "del train\n",
    "del test\n",
    "del augment"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "notify_time": "0",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "207.11956787109375px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
