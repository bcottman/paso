{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import local"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if no test dataset:\n",
    "    train,test    =split\n",
    " = Balance(train)\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=50, n_jobs=-1)\n",
    "\n",
    "bagging n boost = True\n",
    "\n",
    "sklearn.calibration.\n",
    "clf_cal = CalibratedClassifierCV(cv_clf,cv=prefit, cv = k)   resulting in k**2\n",
    "\n",
    "2 modes for kaggle\n",
    "1. train,train-valid, train-test using split-train_test\n",
    "    ratio = .2 verify model against train dataset\n",
    "2. train,train-valid, test using split-train_test \n",
    "   create model from bigger trainset, using ratio = 0.2.0,1 etce\n",
    "use clf_cal. predict on test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-17T21:04:10.356557Z",
     "start_time": "2019-08-17T21:04:05.869247Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# packages in environment at /Users/brucecottman/anaconda3/envs/paso:\r\n",
      "#\r\n",
      "# Name                    Version                   Build  Channel\r\n",
      "_ipyw_jlab_nb_ext_conf    0.1.0                    py37_0  \r\n",
      "absl-py                   0.7.0                    pypi_0    pypi\r\n",
      "alabaster                 0.7.12                   py37_0  \r\n",
      "anaconda-client           1.7.2                    py37_0  \r\n",
      "anaconda-navigator        1.9.6                    py37_0  \r\n",
      "anaconda-project          0.8.2                    py37_0  \r\n",
      "ansimarkup                1.4.0                    pypi_0    pypi\r\n",
      "appnope                   0.1.0                    py37_0  \r\n",
      "appscript                 1.0.1            py37h1de35cc_1  \r\n",
      "asn1crypto                0.24.0                   py37_0  \r\n",
      "astor                     0.7.1                    pypi_0    pypi\r\n",
      "astroid                   2.1.0                    py37_0  \r\n",
      "astropy                   3.1              py37h1de35cc_0  \r\n",
      "atomicwrites              1.2.1                    py37_0  \r\n",
      "attrdict                  2.0.1                    pypi_0    pypi\r\n",
      "attrs                     18.2.0           py37h28b3542_0  \r\n",
      "babel                     2.6.0                    py37_0  \r\n",
      "backcall                  0.1.0                    py37_0  \r\n",
      "backports                 1.0                      py37_1  \r\n",
      "backports.os              0.1.1                    py37_0  \r\n",
      "backports.shutil_get_terminal_size 1.0.0                    py37_2  \r\n",
      "beautifulsoup4            4.6.3                    py37_0  \r\n",
      "better-exceptions-fork    0.2.1.post6              pypi_0    pypi\r\n",
      "bitarray                  0.8.3            py37h1de35cc_0  \r\n",
      "bkcharts                  0.2                      py37_0  \r\n",
      "blas                      1.0                         mkl  \r\n",
      "blaze                     0.11.3                   py37_0  \r\n",
      "bleach                    3.0.2                    py37_0  \r\n",
      "blosc                     1.14.4               hd9629dc_0  \r\n",
      "bokeh                     1.0.4                    py37_0  \r\n",
      "boto                      2.49.0                   py37_0  \r\n",
      "boto3                     1.9.148                  pypi_0    pypi\r\n",
      "botocore                  1.12.148                 pypi_0    pypi\r\n",
      "bottleneck                1.2.1            py37h1d22016_1  \r\n",
      "bzip2                     1.0.6                h1de35cc_5  \r\n",
      "ca-certificates           2019.1.23                     0  \r\n",
      "cairo                     1.14.12              hc4e6be7_4  \r\n",
      "catboost                  0.12.2                   pypi_0    pypi\r\n",
      "category-encoders         2.0.0                    pypi_0    pypi\r\n",
      "certifi                   2019.3.9                 py37_0  \r\n",
      "cffi                      1.11.5           py37h6174b99_1  \r\n",
      "chardet                   3.0.4                    py37_1  \r\n",
      "click                     7.0                      py37_0  \r\n",
      "cloudpickle               0.6.1                    py37_0  \r\n",
      "clyent                    1.2.2                    py37_1  \r\n",
      "colorama                  0.4.1                    py37_0  \r\n",
      "conda-verify              3.1.1                    py37_0  \r\n",
      "contextlib2               0.5.5                    py37_0  \r\n",
      "coverage                  4.5.2                    pypi_0    pypi\r\n",
      "cryptography              2.4.2            py37ha12b0ac_0  \r\n",
      "curl                      7.63.0            ha441bb4_1000  \r\n",
      "cvxpy                     1.0.18                   pypi_0    pypi\r\n",
      "cycler                    0.10.0                   py37_0  \r\n",
      "cymem                     2.0.2                    pypi_0    pypi\r\n",
      "cython                    0.29.2           py37h0a44026_0  \r\n",
      "cytoolz                   0.9.0.1          py37h1de35cc_1  \r\n",
      "dask                      1.0.0                    py37_0  \r\n",
      "dask-core                 1.0.0                    py37_0  \r\n",
      "datashape                 0.5.4                    py37_1  \r\n",
      "dbus                      1.13.2               h760590f_1  \r\n",
      "decorator                 4.3.0                    py37_0  \r\n",
      "defusedxml                0.5.0                    py37_1  \r\n",
      "dill                      0.2.9                    pypi_0    pypi\r\n",
      "distributed               1.25.1                   py37_0  \r\n",
      "docutils                  0.14                     py37_0  \r\n",
      "ecos                      2.0.7.post1              pypi_0    pypi\r\n",
      "entrypoints               0.2.3                    py37_2  \r\n",
      "enum34                    1.1.6                    pypi_0    pypi\r\n",
      "et_xmlfile                1.0.1                    py37_0  \r\n",
      "expat                     2.2.6                h0a44026_0  \r\n",
      "fancyimpute               0.4.2                    pypi_0    pypi\r\n",
      "fastai                    1.0.45                   pypi_0    pypi\r\n",
      "fastcache                 1.0.2            py37h1de35cc_2  \r\n",
      "fastprogress              0.1.19                   pypi_0    pypi\r\n",
      "filelock                  3.0.10                   py37_0  \r\n",
      "findspark                 1.3.0                    pypi_0    pypi\r\n",
      "flask                     1.0.2                    py37_1  \r\n",
      "flask-cors                3.0.7                    py37_0  \r\n",
      "flatbuffers               1.10                     pypi_0    pypi\r\n",
      "fontconfig                2.13.0               h5d5b041_1  \r\n",
      "freetype                  2.9.1                hb4e5f40_0  \r\n",
      "fribidi                   1.0.5                h1de35cc_0  \r\n",
      "funcsigs                  1.0.2                    pypi_0    pypi\r\n",
      "future                    0.17.1                   py37_0  \r\n",
      "gast                      0.2.2                    pypi_0    pypi\r\n",
      "get_terminal_size         1.0.0                h7520d66_0  \r\n",
      "gettext                   0.19.8.1             h15daf44_3  \r\n",
      "gevent                    1.3.7            py37h1de35cc_1  \r\n",
      "glib                      2.56.2               hd9629dc_0  \r\n",
      "glob2                     0.6                      py37_1  \r\n",
      "gmp                       6.1.2                hb37e062_1  \r\n",
      "gmpy2                     2.0.8            py37h6ef4df4_2  \r\n",
      "graphite2                 1.3.13               h2098e52_0  \r\n",
      "graphviz                  2.40.1               hefbbd9a_2  \r\n",
      "greenlet                  0.4.15           py37h1de35cc_0  \r\n",
      "grpcio                    1.18.0                   pypi_0    pypi\r",
      "\r\n",
      "h5py                      2.8.0            py37h878fce3_3  \r\n",
      "harfbuzz                  1.8.8                hb8d4a28_0  \r\n",
      "hdf5                      1.10.2               hfa1e0ec_1  \r\n",
      "heapdict                  1.0.0                    py37_2  \r\n",
      "hpsklearn                 0.1.0                    pypi_0    pypi\r\n",
      "html5lib                  1.0.1                    py37_0  \r\n",
      "hyperopt                  0.1.2                    pypi_0    pypi\r\n",
      "icu                       58.2                 h4b95b61_1  \r\n",
      "idna                      2.8                      py37_0  \r\n",
      "imageio                   2.4.1                    py37_0  \r\n",
      "imagesize                 1.1.0                    py37_0  \r\n",
      "imbalanced-learn          0.4.3                    pypi_0    pypi\r\n",
      "importlib_metadata        0.6                      py37_0  \r\n",
      "intel-openmp              2019.1                      144  \r\n",
      "ipykernel                 5.1.0            py37h39e3cac_0  \r\n",
      "ipython                   7.2.0            py37h39e3cac_0  \r\n",
      "ipython_genutils          0.2.0                    py37_0  \r\n",
      "ipywidgets                7.4.2                    py37_0  \r\n",
      "isort                     4.3.4                    py37_0  \r\n",
      "isoweek                   1.3.3                    pypi_0    pypi\r\n",
      "itsdangerous              1.1.0                    py37_0  \r\n",
      "jbig                      2.1                  h4d881f8_0  \r\n",
      "jdcal                     1.4                      py37_0  \r\n",
      "jedi                      0.13.2                   py37_0  \r\n",
      "jinja2                    2.10                     py37_0  \r\n",
      "jmespath                  0.9.4                    pypi_0    pypi\r\n",
      "joblib                    0.13.2                   pypi_0    pypi\r\n",
      "jpeg                      9b                   he5867d9_2  \r\n",
      "jsonschema                2.6.0                    py37_0  \r\n",
      "jupyter                   1.0.0                    py37_7  \r\n",
      "jupyter-contrib-core      0.3.3                    pypi_0    pypi\r\n",
      "jupyter-contrib-nbextensions 0.5.1                    pypi_0    pypi\r\n",
      "jupyter-highlight-selected-word 0.2.0                    pypi_0    pypi\r\n",
      "jupyter-latex-envs        1.4.6                    pypi_0    pypi\r\n",
      "jupyter-nbextensions-configurator 0.4.1                    pypi_0    pypi\r\n",
      "jupyter_client            5.2.4                    py37_0  \r\n",
      "jupyter_console           6.0.0                    py37_0  \r\n",
      "jupyter_core              4.4.0                    py37_0  \r\n",
      "jupyterlab                0.35.3                   py37_0  \r\n",
      "jupyterlab_server         0.2.0                    py37_0  \r\n",
      "keras                     2.2.4                    pypi_0    pypi\r\n",
      "keras-applications        1.0.7                    pypi_0    pypi\r\n",
      "keras-preprocessing       1.0.9                    pypi_0    pypi\r\n",
      "keyring                   17.0.0                   py37_0  \r\n",
      "kiwisolver                1.0.1            py37h0a44026_0  \r\n",
      "knnimpute                 0.1.0                    pypi_0    pypi\r\n",
      "krb5                      1.16.1               hddcf347_7  \r\n",
      "lazy-object-proxy         1.3.1            py37h1de35cc_2  \r\n",
      "libarchive                3.3.3                h786848e_5  \r\n",
      "libcurl                   7.63.0            h051b688_1000  \r\n",
      "libcxx                    4.0.1                hcfea43d_1  \r\n",
      "libcxxabi                 4.0.1                hcfea43d_1  \r\n",
      "libedit                   3.1.20170329         hb402a30_2  \r\n",
      "libffi                    3.2.1                h475c297_4  \r\n",
      "libgfortran               3.0.1                h93005f0_2  \r\n",
      "libiconv                  1.15                 hdd342a3_7  \r\n",
      "liblief                   0.9.0                h2a1bed3_0  \r\n",
      "libpng                    1.6.35               ha441bb4_0  \r\n",
      "libsodium                 1.0.16               h3efe00b_0  \r\n",
      "libssh2                   1.8.0                ha12b0ac_4  \r\n",
      "libtiff                   4.0.9                hcb84e12_2  \r\n",
      "libxml2                   2.9.8                hab757c2_1  \r\n",
      "libxslt                   1.1.32               hb819dd2_0  \r\n",
      "lightgbm                  2.2.3                    pypi_0    pypi\r\n",
      "llvm-openmp               4.0.1                hcfea43d_1  \r\n",
      "llvmlite                  0.26.0           py37h8c7ce04_0  \r\n",
      "locket                    0.2.0                    py37_1  \r\n",
      "loguru                    0.2.5                    pypi_0    pypi\r\n",
      "lxml                      4.2.5            py37hef8c89e_0  \r\n",
      "lz4-c                     1.8.1.2              h1de35cc_0  \r\n",
      "lzo                       2.10                 h362108e_2  \r\n",
      "markdown                  3.0.1                    pypi_0    pypi\r\n",
      "markupsafe                1.1.0            py37h1de35cc_0  \r\n",
      "matplotlib                3.0.2            py37h54f8f79_0  \r\n",
      "mccabe                    0.6.1                    py37_1  \r\n",
      "mistune                   0.8.4            py37h1de35cc_0  \r\n",
      "mkl                       2019.1                      144  \r\n",
      "mkl-service               1.1.2            py37hfbe908c_5  \r\n",
      "mkl_fft                   1.0.6            py37h27c97d8_0  \r\n",
      "mkl_random                1.0.2            py37h27c97d8_0  \r\n",
      "mock                      2.0.0                    pypi_0    pypi\r\n",
      "modin                     0.4.0                    pypi_0    pypi\r\n",
      "more-itertools            4.3.0                    py37_0  \r\n",
      "mpc                       1.1.0                h6ef4df4_1  \r\n",
      "mpfr                      4.0.1                h3018a27_3  \r\n",
      "mpmath                    1.1.0                    py37_0  \r\n",
      "msgpack-numpy             0.4.3.2                  pypi_0    pypi\r\n",
      "msgpack-python            0.5.6            py37h04f5b5a_1  \r\n",
      "multipledispatch          0.6.0                    py37_0  \r\n",
      "multiprocess              0.70.7                   pypi_0    pypi\r\n",
      "murmurhash                1.0.1                    pypi_0    pypi\r\n",
      "navigator-updater         0.2.1                    py37_0  \r\n",
      "nbconvert                 5.4.1                    pypi_0    pypi\r\n",
      "nbformat                  4.4.0                    py37_0  \r\n",
      "nbsphinx                  0.4.2                    pypi_0    pypi\r\n",
      "ncurses                   6.1                  h0a44026_1  \r\n",
      "networkx                  2.2                      py37_1  \r\n",
      "ninja                     1.8.2            py37h04f5b5a_1  \r\n",
      "nltk                      3.4                      py37_1  \r\n",
      "nose                      1.3.7                    py37_2  \r\n",
      "notebook                  5.7.4                    py37_0  \r\n",
      "np-utils                  0.5.9.0                  pypi_0    pypi\r\n",
      "numba                     0.41.0           py37h6440ff4_0  \r\n",
      "numexpr                   2.6.8            py37h7413580_0  \r\n",
      "numpy                     1.15.0                   pypi_0    pypi\r\n",
      "numpydoc                  0.8.0                    py37_0  \r\n",
      "nvidia-ml-py3             7.352.0                  pypi_0    pypi\r\n",
      "odo                       0.5.1                    py37_0  \r\n",
      "olefile                   0.46                     py37_0  \r\n",
      "openpyxl                  2.5.12                   py37_0  \r\n",
      "openssl                   1.1.1b               h1de35cc_1  \r\n",
      "osqp                      0.5.0                    pypi_0    pypi\r\n",
      "packaging                 18.0                     py37_0  \r\n",
      "pandas                    0.24.1                   pypi_0    pypi\r\n",
      "pandas-summary            0.0.6                    pypi_0    pypi\r\n",
      "pandoc                    1.19.2.1             ha5e8f32_1  \r\n",
      "pandocfilters             1.4.2                    py37_1  \r\n",
      "pango                     1.42.4               h060686c_0  \r\n",
      "parso                     0.3.1                    py37_0  \r\n",
      "partd                     0.3.9                    py37_0  \r\n",
      "path.py                   11.5.0                   py37_0  \r\n",
      "pathlib2                  2.3.3                    py37_0  \r\n",
      "patsy                     0.5.1                    py37_0  \r\n",
      "pbr                       5.1.2                    pypi_0    pypi\r\n",
      "pcre                      8.42                 h378b8a2_0  \r\n",
      "pep8                      1.7.1                    py37_0  \r\n",
      "pexpect                   4.6.0                    py37_0  \r\n",
      "pickleshare               0.7.5                    py37_0  \r\n",
      "pillow                    5.3.0            py37hb68e598_0  \r\n",
      "pip                       19.1.1                   pypi_0    pypi\r\n",
      "pixman                    0.38.0               h1de35cc_0  \r\n",
      "pkginfo                   1.4.2                    py37_1  \r\n",
      "plac                      0.9.6                    pypi_0    pypi\r\n",
      "plotly                    3.6.1                    pypi_0    pypi\r\n",
      "pluggy                    0.8.0                    py37_0  \r\n",
      "ply                       3.11                     py37_0  \r\n",
      "preshed                   2.0.1                    pypi_0    pypi\r\n",
      "probscale                 0.2.3                    pypi_0    pypi\r\n",
      "prometheus_client         0.5.0                    py37_0  \r\n",
      "prompt_toolkit            2.0.7                    py37_0  \r\n",
      "protobuf                  3.6.1                    pypi_0    pypi\r\n",
      "psutil                    5.4.8            py37h1de35cc_0  \r\n",
      "ptyprocess                0.6.0                    py37_0  \r\n",
      "py                        1.7.0                    py37_0  \r\n",
      "py-lief                   0.9.0            py37hd4eaf27_0  \r\n",
      "py4j                      0.10.7                   pypi_0    pypi\r\n",
      "pyarrow                   0.12.0                   pypi_0    pypi\r\n",
      "pycodestyle               2.4.0                    py37_0  \r\n",
      "pycosat                   0.6.3            py37h1de35cc_0  \r\n",
      "pycparser                 2.19                     py37_0  \r\n",
      "pycrypto                  2.6.1            py37h1de35cc_9  \r\n",
      "pycurl                    7.43.0.2         py37ha12b0ac_0  \r\n",
      "pydataset                 0.2.0                    pypi_0    pypi\r\n",
      "pydot                     1.3.0                    py37_1  \r\n",
      "pydot-ng                  2.0.0                    pypi_0    pypi\r\n",
      "pyflakes                  2.0.0                    py37_0  \r\n",
      "pygments                  2.3.1                    py37_0  \r\n",
      "pylint                    2.2.2                    py37_0  \r\n",
      "pymongo                   3.9.0                    pypi_0    pypi\r\n",
      "pyodbc                    4.0.25           py37h0a44026_0  \r\n",
      "pyopenssl                 18.0.0                   py37_0  \r\n",
      "pyparsing                 2.3.0                    py37_0  \r\n",
      "pyqt                      5.9.2            py37h655552a_2  \r\n",
      "pysocks                   1.6.8                    py37_0  \r\n",
      "pyspark                   2.4.3                    pypi_0    pypi\r\n",
      "pytables                  3.4.4            py37h13cba08_0  \r\n",
      "pytest                    4.0.2                    py37_0  \r\n",
      "pytest-arraydiff          0.3              py37h39e3cac_0  \r\n",
      "pytest-astropy            0.5.0                    py37_0  \r\n",
      "pytest-doctestplus        0.2.0                    py37_0  \r\n",
      "pytest-openfiles          0.3.1                    py37_0  \r\n",
      "pytest-remotedata         0.3.1                    py37_0  \r\n",
      "python                    3.7.1                haf84260_7  \r\n",
      "python-dateutil           2.7.5                    py37_0  \r\n",
      "python-libarchive-c       2.8                      py37_6  \r\n",
      "python.app                2                        py37_9  \r\n",
      "pytorch                   1.0.1                   py3.7_2    pytorch\r\n",
      "pytz                      2018.7                   py37_0  \r\n",
      "pywavelets                1.0.1            py37h1d22016_0  \r\n",
      "pyyaml                    3.13             py37h1de35cc_0  \r\n",
      "pyzmq                     17.1.2           py37h1de35cc_0  \r\n",
      "qt                        5.9.7                h468cd18_1  \r\n",
      "qtawesome                 0.5.3                    py37_0  \r\n",
      "qtconsole                 4.4.3                    py37_0  \r\n",
      "qtpy                      1.5.2                    py37_0  \r\n",
      "ray                       0.6.2                    pypi_0    pypi\r\n",
      "readline                  7.0                  h1de35cc_5  \r\n",
      "redis                     3.2.1                    pypi_0    pypi\r\n",
      "regex                     2018.1.10                pypi_0    pypi\r\n",
      "requests                  2.21.0                   py37_0  \r\n",
      "retrying                  1.3.3                    pypi_0    pypi\r\n",
      "rope                      0.11.0                   py37_0  \r\n",
      "ruamel_yaml               0.15.46          py37h1de35cc_0  \r\n",
      "s3fs                      0.2.1                    pypi_0    pypi\r\n",
      "s3transfer                0.2.0                    pypi_0    pypi\r\n",
      "scikit-image              0.14.1           py37h0a44026_0  \r\n",
      "scikit-learn              0.20.1           py37h27c97d8_0  \r\n",
      "scipy                     1.1.0            py37h1410ff5_2  \r\n",
      "scs                       2.0.2                    pypi_0    pypi\r\n",
      "seaborn                   0.9.0                    py37_0  \r\n",
      "send2trash                1.5.0                    py37_0  \r\n",
      "setuptools                40.6.3                   py37_0  \r\n",
      "simplegeneric             0.8.1                    py37_2  \r\n",
      "singledispatch            3.4.0.3                  py37_0  \r\n",
      "sip                       4.19.8           py37h0a44026_0  \r\n",
      "six                       1.12.0                   py37_0  \r\n",
      "sklearn                   0.0                      pypi_0    pypi\r\n",
      "sklearn-pandas            1.8.0                    pypi_0    pypi\r\n",
      "snappy                    1.1.7                he62c110_3  \r\n",
      "snowballstemmer           1.2.1                    py37_0  \r\n",
      "sortedcollections         1.0.1                    py37_0  \r\n",
      "sortedcontainers          2.1.0                    py37_0  \r\n",
      "spacy                     2.0.18                   pypi_0    pypi\r\n",
      "sphinx                    1.8.2                    py37_0  \r\n",
      "sphinx-automodapi         0.10                     pypi_0    pypi\r\n",
      "sphinx-gallery            0.2.0                    pypi_0    pypi\r\n",
      "sphinx-rtd-theme          0.4.3                    pypi_0    pypi\r\n",
      "sphinxcontrib             1.0                      py37_1  \r\n",
      "sphinxcontrib-websupport  1.1.0                    py37_1  \r\n",
      "spyder                    3.3.2                    py37_0  \r\n",
      "spyder-kernels            0.3.0                    py37_0  \r\n",
      "sqlalchemy                1.2.15           py37h1de35cc_0  \r\n",
      "sqlite                    3.26.0               ha441bb4_0  \r\n",
      "statsmodels               0.9.0            py37h1d22016_0  \r\n",
      "sympy                     1.3                      py37_0  \r\n",
      "tblib                     1.3.2                    py37_0  \r\n",
      "tensorboard               1.12.2                   pypi_0    pypi\r\n",
      "tensorflow                1.13.0rc2                pypi_0    pypi\r\n",
      "tensorflow-estimator      1.13.0rc0                pypi_0    pypi\r\n",
      "termcolor                 1.1.0                    pypi_0    pypi\r\n",
      "terminado                 0.8.1                    py37_1  \r\n",
      "testpath                  0.4.2                    py37_0  \r\n",
      "thinc                     6.12.1                   pypi_0    pypi\r\n",
      "tk                        8.6.8                ha441bb4_0  \r\n",
      "toolz                     0.9.0                    py37_0  \r\n",
      "torchvision               0.2.1                      py_2    pytorch\r\n",
      "tornado                   5.1.1            py37h1de35cc_0  \r\n",
      "tqdm                      4.28.1           py37h28b3542_0  \r\n",
      "traitlets                 4.3.2                    py37_0  \r\n",
      "typing                    3.6.6                    pypi_0    pypi\r\n",
      "ujson                     1.35                     pypi_0    pypi\r\n",
      "unicodecsv                0.14.1                   py37_0  \r\n",
      "unixodbc                  2.3.7                h1de35cc_0  \r\n",
      "urllib3                   1.24.1                   py37_0  \r\n",
      "wand                      0.5.1                    pypi_0    pypi\r\n",
      "wcwidth                   0.1.7                    py37_0  \r\n",
      "webencodings              0.5.1                    py37_1  \r\n",
      "werkzeug                  0.14.1                   py37_0  \r\n",
      "wheel                     0.32.3                   py37_0  \r\n",
      "widgetsnbextension        3.4.2                    py37_0  \r\n",
      "wrapt                     1.10.11          py37h1de35cc_2  \r\n",
      "wurlitzer                 1.0.2                    py37_0  \r\n",
      "xgboost                   0.81                     pypi_0    pypi\r\n",
      "xlrd                      1.2.0                    py37_0  \r\n",
      "xlsxwriter                1.1.2                    py37_0  \r\n",
      "xlwings                   0.15.1                   py37_0  \r\n",
      "xlwt                      1.3.0                    py37_0  \r\n",
      "xz                        5.2.4                h1de35cc_4  \r\n",
      "yaml                      0.1.7                hc338f04_2  \r\n",
      "zeromq                    4.2.5                h0a44026_1  \r\n",
      "zict                      0.1.3                    py37_0  \r\n",
      "zlib                      1.2.11               h1de35cc_3  \r\n",
      "zstd                      1.3.7                h5bba6e5_0  \r\n"
     ]
    }
   ],
   "source": [
    "!conda list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-17T21:04:10.379878Z",
     "start_time": "2019-08-17T21:04:10.359648Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/brucecottman/Documents/PROJECTS/paso'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "__file__ = !cd .. ;pwd\n",
    "__file__ = __file__[0]\n",
    "__file__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-17T21:04:10.764898Z",
     "start_time": "2019-08-17T21:04:10.382145Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/brucecottman/Documents/PROJECTS/paso/lessons',\n",
       " '/Users/brucecottman/anaconda3/envs/paso/lib/python37.zip',\n",
       " '/Users/brucecottman/anaconda3/envs/paso/lib/python3.7',\n",
       " '/Users/brucecottman/anaconda3/envs/paso/lib/python3.7/lib-dynload',\n",
       " '',\n",
       " '/Users/brucecottman/.local/lib/python3.7/site-packages',\n",
       " '/Users/brucecottman/anaconda3/envs/paso/lib/python3.7/site-packages',\n",
       " '/Users/brucecottman/anaconda3/envs/paso/lib/python3.7/site-packages/aeosa',\n",
       " '/Users/brucecottman/anaconda3/envs/paso/lib/python3.7/site-packages/IPython/extensions',\n",
       " '/Users/brucecottman/.ipython',\n",
       " '/Users/brucecottman/Documents/PROJECTS/paso']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "from random import random\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "sys.path.append(__file__)\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-17T21:04:12.241539Z",
     "start_time": "2019-08-17T21:04:10.768464Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARN: OMP_NUM_THREADS=None =>\n",
      "... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n",
      "paso 17.8.2019 17:04:12 INFO Log started\n",
      "paso 17.8.2019 17:04:12 INFO ========================================\n",
      "paso 17.8.2019 17:04:12 INFO Read in parameter file: ../parameters/lesson.3.yaml\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas_summary import DataFrameSummary\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import multiprocessing\n",
    "\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import cm\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "color = sns.color_palette()\n",
    "sns.set(rc={'figure.figsize':(6,4)})\n",
    "from paso.base import Paso,Log,PasoError\n",
    "from loguru import logger\n",
    "session = Paso(parameters_filepath='../parameters/lesson.3.yaml').startup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-17T21:04:12.313067Z",
     "start_time": "2019-08-17T21:04:12.245170Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paso 17.8.2019 17:04:12 INFO ========================================\n",
      "paso 17.8.2019 17:04:12 INFO Read in parameter file: ../parameters/lesson.3.yaml\n"
     ]
    }
   ],
   "source": [
    "from paso.base import Paso,Log,PasoError,Param,NameToClass\n",
    "from loguru import logger\n",
    "session = Paso(parameters_filepath='../parameters/lesson.3.yaml').startup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we saw in [lesson-1](), we need to startup **paso** services."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-17T21:04:12.454568Z",
     "start_time": "2019-08-17T21:04:12.315032Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paso 17.8.2019 17:04:12 INFO ========================================\n",
      "paso 17.8.2019 17:04:12 INFO Read in parameter file: ../parameters/lesson.3.yaml\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas_summary import DataFrameSummary\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import multiprocessing\n",
    "\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import cm\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "color = sns.color_palette()\n",
    "\n",
    "from paso.base import Paso,Log,PasoError\n",
    "from loguru import logger\n",
    "session = Paso(parameters_filepath='../parameters/lesson.3.yaml').startup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ToyÂ Example Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **paso** class is a general method to read in datasets and return them as dataframes. For now, we can use them. In a future lesson we will cover  ``Inputer`` in  detail.  All available ``Inputer`` methods are shown with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-17T21:04:12.580846Z",
     "start_time": "2019-08-17T21:04:12.456871Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['exec', 'cvs', 'xls', 'xlsm', 'text', 'image2D', 'image3D']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from paso.pre.inputers import Inputer,Splitter\n",
    "dataset_name = 'yeast3'\n",
    "inputer = Inputer(ontological_filepath='../ontologies/pre/inputers/'+dataset_name+'.yaml')\n",
    "inputer.inputers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-17T21:04:12.708488Z",
     "start_time": "2019-08-17T21:04:12.582776Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train', 'valid', 'test', 'sampleSubmission', 'directory_path']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputer.datasets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us start with a toy dataset to class balance. we load the ``iris``data set, into the ``flower`` dataframe.  The feature ``TypeOf`` will contain the class target values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-17T21:04:12.836665Z",
     "start_time": "2019-08-17T21:04:12.710740Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paso 17.8.2019 17:04:12 INFO Loaded Ontological file:../ontologies/pre/inputers/yeast3.yaml \n",
      "paso 17.8.2019 17:04:12 INFO \n",
      " kind-name:cvs\n",
      " description:yeast3 dataset\n",
      " genus: Inputer\n",
      " type: dataset\n",
      " kwargs: {'target': 'Class', 'directory_path': '/Users/brucecottman/Documents/PROJECTS/paso/data/', 'train': 'yeast3.csv'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Class'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yeast3 = inputer.transform()\n",
    "inputer.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-17T21:04:12.955437Z",
     "start_time": "2019-08-17T21:04:12.838613Z"
    }
   },
   "outputs": [],
   "source": [
    "yeast3[inputer.target]= pd.Categorical(yeast3[inputer.target])\n",
    "yeast3[inputer.target]= yeast3[inputer.target].cat.codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A short aside on ontological files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of using keyword arguments cemented in code, I will use an ontological file. One working definition of ontological (from Wikipedia) is:\n",
    "\n",
    "    \"showing the relations between the concepts and categories in a subject area or domain\".\n",
    "\n",
    "We are using ontological files because:\n",
    "- the description of an object (dataset, model,etc.) can be changed without changing code\n",
    "- the parsing performance of an ontological file and python are about the same as both use dynamic typing. This probably would not be case for statically typed language. However, an object's metadata parsing compute is very tiny compared to the action(s) performed on or by the object in all cases encountered so far.  \n",
    "\n",
    "We will found out if ontological files have a measurable overhead as we port **paso** to other frameworks (such as **RAPIDS**) or statically-typed languages (such as ``swift``). At much of python's workhorse packages are in fast, statically-typed ``C``, so I doubt it.\n",
    "\n",
    "Ontological files consist of hierarchy of key-value pairs.  In a future lesson we will cover Ontological files in  detail. [Different Ontological files can be viewed here.](https://github.com/bcottman/paso/tree/master/ontologies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-17T21:04:13.283844Z",
     "start_time": "2019-08-17T21:04:12.957766Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mcg</th>\n",
       "      <th>Gvh</th>\n",
       "      <th>Alm</th>\n",
       "      <th>Mit</th>\n",
       "      <th>Erl</th>\n",
       "      <th>Pox</th>\n",
       "      <th>Vac</th>\n",
       "      <th>Nuc</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1484</td>\n",
       "      <td>1484</td>\n",
       "      <td>1484</td>\n",
       "      <td>1484</td>\n",
       "      <td>1484</td>\n",
       "      <td>1484</td>\n",
       "      <td>1484</td>\n",
       "      <td>1484</td>\n",
       "      <td>1484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.500121</td>\n",
       "      <td>0.499933</td>\n",
       "      <td>0.500034</td>\n",
       "      <td>0.261186</td>\n",
       "      <td>0.504717</td>\n",
       "      <td>0.0075</td>\n",
       "      <td>0.499885</td>\n",
       "      <td>0.276199</td>\n",
       "      <td>0.109838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.137299</td>\n",
       "      <td>0.123924</td>\n",
       "      <td>0.0866702</td>\n",
       "      <td>0.137098</td>\n",
       "      <td>0.048351</td>\n",
       "      <td>0.0756827</td>\n",
       "      <td>0.0577966</td>\n",
       "      <td>0.106491</td>\n",
       "      <td>0.312793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.11</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.41</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.49</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.58</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.73</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>counts</th>\n",
       "      <td>1484</td>\n",
       "      <td>1484</td>\n",
       "      <td>1484</td>\n",
       "      <td>1484</td>\n",
       "      <td>1484</td>\n",
       "      <td>1484</td>\n",
       "      <td>1484</td>\n",
       "      <td>1484</td>\n",
       "      <td>1484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uniques</th>\n",
       "      <td>81</td>\n",
       "      <td>79</td>\n",
       "      <td>53</td>\n",
       "      <td>78</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>48</td>\n",
       "      <td>68</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>missing</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>missing_perc</th>\n",
       "      <td>0%</td>\n",
       "      <td>0%</td>\n",
       "      <td>0%</td>\n",
       "      <td>0%</td>\n",
       "      <td>0%</td>\n",
       "      <td>0%</td>\n",
       "      <td>0%</td>\n",
       "      <td>0%</td>\n",
       "      <td>0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>types</th>\n",
       "      <td>numeric</td>\n",
       "      <td>numeric</td>\n",
       "      <td>numeric</td>\n",
       "      <td>numeric</td>\n",
       "      <td>bool</td>\n",
       "      <td>numeric</td>\n",
       "      <td>numeric</td>\n",
       "      <td>numeric</td>\n",
       "      <td>bool</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Mcg       Gvh        Alm       Mit       Erl        Pox  \\\n",
       "count             1484      1484       1484      1484      1484       1484   \n",
       "mean          0.500121  0.499933   0.500034  0.261186  0.504717     0.0075   \n",
       "std           0.137299  0.123924  0.0866702  0.137098  0.048351  0.0756827   \n",
       "min               0.11      0.13       0.21         0       0.5          0   \n",
       "25%               0.41      0.42       0.46      0.17       0.5          0   \n",
       "50%               0.49      0.49       0.51      0.22       0.5          0   \n",
       "75%               0.58      0.57       0.55      0.32       0.5          0   \n",
       "max                  1         1          1         1         1       0.83   \n",
       "counts            1484      1484       1484      1484      1484       1484   \n",
       "uniques             81        79         53        78         2          3   \n",
       "missing              0         0          0         0         0          0   \n",
       "missing_perc        0%        0%         0%        0%        0%         0%   \n",
       "types          numeric   numeric    numeric   numeric      bool    numeric   \n",
       "\n",
       "                    Vac       Nuc     Class  \n",
       "count              1484      1484      1484  \n",
       "mean           0.499885  0.276199  0.109838  \n",
       "std           0.0577966  0.106491  0.312793  \n",
       "min                   0         0         0  \n",
       "25%                0.48      0.22         0  \n",
       "50%                0.51      0.22         0  \n",
       "75%                0.53       0.3         0  \n",
       "max                0.73         1         1  \n",
       "counts             1484      1484      1484  \n",
       "uniques              48        68         2  \n",
       "missing               0         0         0  \n",
       "missing_perc         0%        0%        0%  \n",
       "types           numeric   numeric      bool  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DataFrameSummary(yeast3).summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## It is important to split first before balancing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before training the learner it is very important to balance only the dataset we will train on. We want to know the effect of balancing data on the learner, while not corrupting our validation  dataset with augmented  data that balances the classes.\n",
    "\n",
    "Validation is drawn from the initial train dataset in the hopes it is a sample of the past and future data that the test dataset will be drawn from. The other case where train, valid, test are sampled from the original dataset is covered by splitting the initial dataset to result in train and valid. Then split on train again to get train and test. The order does not matter so long as the second split is also on the train dataset ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-17T21:04:13.614823Z",
     "start_time": "2019-08-17T21:04:13.286163Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paso 17.8.2019 17:04:13 INFO Loaded Ontological file:../ontologies/pre/inputers/test_size_30.yaml \n",
      "paso 17.8.2019 17:04:13 INFO \n",
      " kind-name:TrTest_split\n",
      " description:split into train-test dataset\n",
      " genus: Splitter\n",
      " type: None\n",
      " kwargs: {'test_size': 0.3, 'shuffle': True, 'stratify': True, 'random_state': 66}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gvh</th>\n",
       "      <th>Alm</th>\n",
       "      <th>Erl</th>\n",
       "      <th>Mcg</th>\n",
       "      <th>Mit</th>\n",
       "      <th>Nuc</th>\n",
       "      <th>Pox</th>\n",
       "      <th>Vac</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1371</th>\n",
       "      <td>0.60</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>0.41</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1142</th>\n",
       "      <td>0.63</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705</th>\n",
       "      <td>0.41</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1259</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Gvh   Alm  Erl   Mcg   Mit   Nuc  Pox   Vac\n",
       "1371   0.60  0.65  0.5  0.31  0.18  0.22  0.0  0.46\n",
       "563    0.41  0.58  0.5  0.45  0.48  0.64  0.0  0.53\n",
       "1142   0.63  0.45  0.5  0.50  0.13  0.32  0.0  0.45\n",
       "705    0.41  0.47  0.5  0.24  0.16  0.38  0.0  0.51\n",
       "1259   0.50  0.48  0.5  0.50  0.17  0.26  0.0  0.47"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splitter = Splitter(ontological_filepath='../ontologies/pre/inputers/test_size_30.yaml')\n",
    "train,test=splitter.transform(yeast3,target=inputer.target)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The argument ratio is the amount of the dataset to assign to the validation (test) dataset. In this case,\n",
    "``X``and ``y`` datasets into training set(50\\%) and test set(50\\%). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: A ``valid`` dataset is not made as we are not tuning learner parameters in this lesson. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## paso Class for Handling Imbalanced Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "All available class balance strategies are shown with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-17T21:04:13.740669Z",
     "start_time": "2019-08-17T21:04:13.617174Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RanZOverSample',\n",
       " 'SMOTE',\n",
       " 'ADASYN',\n",
       " 'BorderLineSMOTE',\n",
       " 'SVMSMOTE',\n",
       " 'SMOTENC',\n",
       " 'RandomUnderSample',\n",
       " 'ClusterCentroids',\n",
       " 'NearMiss',\n",
       " 'EditedNearestNeighbour',\n",
       " 'RepeatedEditedNearestNeighbours',\n",
       " 'CondensedNearestNeighbour',\n",
       " 'OneSidedSelection']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from paso.pre.cleaners import Class_Balance\n",
    "class_balancer = Class_Balance(ontological_filepath='../ontologies/cleaners/SMOTE.yaml')\n",
    "class_balancer.classBalancers()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-25T20:11:00.840933Z",
     "start_time": "2019-07-25T20:11:00.787237Z"
    },
    "hidden": true
   },
   "source": [
    "I am going to oversample the minority classes by using ``SMOOT``. I reccomend [Handling imbalanced datasets in machine learning](https://towardsdatascience.com/handling-imbalanced-datasets-in-machine-learning-7a0e84220f28) for more detail on how to balance class imbalanced datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-17T21:04:14.258586Z",
     "start_time": "2019-08-17T21:04:13.743133Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '_boiler_plate' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/Documents/PROJECTS/paso\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtargetFeature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mclass_balancer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mClass_Balance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0montological_filepath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'../ontologies/pre/cleaners/SMOTE.yaml'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclass_balancer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/PROJECTS/paso/paso/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    525\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 527\u001b[0;31m                 \u001b[0mobjecty\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_boiler_plate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnarg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    528\u001b[0m                 \"\"\"\n\u001b[1;32m    529\u001b[0m                  \u001b[0mall\u001b[0m \u001b[0mkeywords\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0mmethods\u001b[0m \u001b[0mare\u001b[0m \u001b[0mlisted\u001b[0m \u001b[0mhere\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name '_boiler_plate' is not defined"
     ]
    }
   ],
   "source": [
    "targetFeature = inputer.target\n",
    "class_balancer = Class_Balance(ontological_filepath='../ontologies/pre/cleaners/SMOTE.yaml')\n",
    "train = class_balancer.transform(train,target=inputer.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-17T21:04:14.262743Z",
     "start_time": "2019-08-17T21:04:05.897Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "DataFrameSummary(train).summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "``Class_Balance`` did not change the ``Flower-train`` dataframe as the ``iris``dataset comes class balanced. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-17T21:04:14.264231Z",
     "start_time": "2019-08-17T21:04:05.899Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train[['Mcg',inputer.target]].groupby([inputer.target]).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-17T21:04:14.265786Z",
     "start_time": "2019-08-17T21:04:05.901Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test[['Mcg',inputer.target]].groupby([inputer.target]).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## A short aside on cross-validation and classification train/predict model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "In an future lesson, I will cover in detail how to use **paso**'s cross-validation for learners that can train and then predict. In the meantime, you can find a good [overview of cross-validation](https://towardsdatascience.com/train-test-split-and-cross-validation-in-python-80b61beca4b6) and a [detailed discussion of cross-validation](https://scikit-learn.org/stable/modules/cross_validation.html#computing-cross-validated-metrics).\n",
    "\n",
    "In this lesson, we use **repeated random sub-sampling** or ``sklearn.ensemble.BaggingClassifier``. This is hopefully a good choice for the class stratified datasets we will be using.\n",
    "\n",
    "Similar to **K-Fold cross-validation** , we set a value for ``n_estimators`` which signifies the number of times we will train our learner on a random subset of the train dataset. However, in this case ``n_estimator``  will not represent the number of learners.\n",
    "Instead, on each training iteration, we randomly select data points for the train folds. The number of data points we select will be a certain percentage we set for the initial trainng set. For example, if we select ``max_samples= 0.90``, then each iteration we will apply the learner to randomly selected 90% of the data points of our original train dataset.  This is similar to ``K-fold`` with ``K=10``, except the samples in folds are chosen at random and it will be more computational expensive if  ``n_estimator >> K``.\n",
    "\n",
    " You should note that ``BaggingClassifier`` will need keep ``n_estimators`` dataset+tree around. If you have a large dataset, it maybe required to pare the dataset down by removing the weakest predictive features in the initial cleaning. I should have done this with the **otto-group**, but I did not. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the RandomForest learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-17T21:04:14.267416Z",
     "start_time": "2019-08-17T21:04:05.904Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from paso.learners.learners import Learner\n",
    "learner = Learner(ontological_filepath='../ontologies/learners/RandomForestClassification.sm.yaml',target='TypeOf')\n",
    "learner.train(train,target=inputer.target\n",
    "              ,checkpoint='diabetesRandomForest1.ckp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the population of each of the Iris classes is about the same, the accuracy and the F1-score are almost equal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-17T21:04:14.269022Z",
     "start_time": "2019-08-17T21:04:05.906Z"
    }
   },
   "outputs": [],
   "source": [
    "learner.predict(test,measure=True)\n",
    "learner.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-17T21:04:14.270513Z",
     "start_time": "2019-08-17T21:04:05.907Z"
    }
   },
   "outputs": [],
   "source": [
    "learner.wrong_predicted_class,learner.wrong_predicted_class.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, very good scores using ``RandomForestClassifier`` on 70% of dataset train and 30% for of dataset for validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting there were correct class assignments but logloss got slightly worse when we balanced the classes using ``SMOTE``."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using splitter, we can shuffle rows around and get different ``piam-diabetes`` train and test datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augment the ``yeast3``dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can augment (increase by 10\\% the amount data) with  synthetic data generated by a claas imbalence scheme,  ``SMOOT``. Just ``TypeOf=0`` needs 15(10%) rows (3 classes of 5 rows) of synthetic data to balance the classes. The result is similar to image augmention in that we accomplished structured data augmentation by increasing the row count ``Isis``dataset with synthetic data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-17T21:04:14.272196Z",
     "start_time": "2019-08-17T21:04:05.910Z"
    }
   },
   "outputs": [],
   "source": [
    "from paso.pre.cleaners import Augment_by_Class\n",
    "augmenter = Augment_by_Class(ontological_filepath='../ontologies/pre/cleaners/SMOTE.yaml')\n",
    "\n",
    "augment =augmenter.transform(train,target=inputer.target,ratio=0.5)\n",
    "DataFrameSummary(augment).summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the ``mean``, ``std`` and other statistics have slightly changed. Also, the count has inreased by 10% or augmented a structured dataset by 10%. Why do expect slight and not large change in the dataset statistics?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train , Predict Augmented Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-17T21:04:14.273588Z",
     "start_time": "2019-08-17T21:04:05.912Z"
    }
   },
   "outputs": [],
   "source": [
    "learner.train(augment,target=inputer.target)\n",
    "learner.predict(test,measure=True)\n",
    "learner.metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-01T21:10:09.297466Z",
     "start_time": "2019-07-01T21:09:40.152Z"
    }
   },
   "source": [
    "Hmmm, seemed to improve scores a little bit. Let us try 100% augmentation or double the number of rows in the  ``Flower`` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-17T21:04:14.274959Z",
     "start_time": "2019-08-17T21:04:05.914Z"
    }
   },
   "outputs": [],
   "source": [
    "learner.wrong_predicted_class.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmentation ``pima-diabetes`` train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-17T21:04:14.276823Z",
     "start_time": "2019-08-17T21:04:05.916Z"
    }
   },
   "outputs": [],
   "source": [
    "def grinder(N,M,S,input_file):\n",
    "    score = np.zeros((S,N,M+2), dtype=np.float32)\n",
    "    scores = {}           \n",
    "\n",
    "    for i in tqdm(range(N)):\n",
    "        inputer = Inputer(ontological_filepath=input_file)\n",
    "        df = inputer.transform(verbose=False)\n",
    "        df[inputer.target]= pd.Categorical(df[inputer.target])\n",
    "        df[inputer.target]= df[inputer.target].cat.codes\n",
    "        splitter = Splitter(ontological_filepath='../ontologies/pre/inputers/split-stratify-shuffle-30.yaml')\n",
    "        train,test=splitter.transform(df,verbose=False\n",
    "                                      ,target=inputer.target\n",
    "                                      ,random_state=22*(i+1))\n",
    "        # do not balancee       \n",
    "        learner = Learner(ontological_filepath='../ontologies/learners/RandomForestClassification.sm.yaml',target='TypeOf')\n",
    "        learner.train(train,target=inputer.target,verbose=False\n",
    "                      ,checkpoint='diabetesRandomForest1.ckp')  \n",
    "        learner.predict(test,measure=True)\n",
    "        score[0,i,0] = learner.metrics['logloss']\n",
    "        score[1,i,0] = learner.metrics['AOC']\n",
    "        #Class_Balance\n",
    "        class_balancer = Class_Balance(ontological_filepath='../ontologies/pre/cleaners/SMOTE.yaml')\n",
    "        train = class_balancer.transform(train,target=inputer.target,verbose=False)\n",
    "        learner = Learner(ontological_filepath='../ontologies/learners/RandomForestClassification.pima.yaml',target='TypeOf')\n",
    "        learner.train(train,target=inputer.target,verbose=False\n",
    "                      ,checkpoint='diabetesRandomForest2.ckp')\n",
    "        learner.predict(test,measure=True)\n",
    "        score[0,i,1] = learner.metrics['logloss']\n",
    "        score[1,i,1] = learner.metrics['AOC']\n",
    "        #augment\n",
    "        augment = train\n",
    "        for j in range(M):\n",
    "        # 2*1 augmentation\n",
    "            augmenter = Augment_by_Class(ontological_filepath='../ontologies/pre/cleaners/SMOTE.yaml')\n",
    "            ratio = 1.0\n",
    "            targetFeature =  inputer.target\n",
    "            augment =augmenter.transform(augment,target=inputer.target,ratio=1.0,verbose=False)\n",
    "            learner = Learner(ontological_filepath='../ontologies/learners/RandomForestClassification.sm.yaml',target='TypeOf')\n",
    "            learner.train(augment,target=inputer.target,verbose=False\n",
    "                          ,checkpoint='diabetesRandomForest'+str(i+2)+'.ckp')\n",
    "            learner.predict(test,measure=True)\n",
    "            score[0,i,j+2] = learner.metrics['logloss']\n",
    "            score[1,i,j+2] = learner.metrics['AOC']\n",
    "        learner.wrong_predicted_class\n",
    "    scores['logloss'] = score[0,:,:]\n",
    "    scores['AOC'] = score[1,:,:]\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-17T21:04:14.278435Z",
     "start_time": "2019-08-17T21:04:05.918Z"
    }
   },
   "outputs": [],
   "source": [
    "N = 10  #trial\n",
    "M = 4 # augmentation 2**M\n",
    "S= 2 #scores to keep\n",
    "scores = grinder(N,M,S,'../ontologies/pre/inputers/yeast3.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-17T21:04:14.280102Z",
     "start_time": "2019-08-17T21:04:05.920Z"
    }
   },
   "outputs": [],
   "source": [
    "baseline = scores['logloss'][:,0]\n",
    "aug_balance = np.mean(scores['logloss'][:,1:2],axis=1)\n",
    "baseline,aug_balance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-17T21:04:14.281729Z",
     "start_time": "2019-08-17T21:04:05.922Z"
    }
   },
   "outputs": [],
   "source": [
    "np.mean(baseline/aug_balance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-17T21:04:14.283387Z",
     "start_time": "2019-08-17T21:04:05.924Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(x=baseline ,y=baseline/aug_balance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-17T21:04:14.285478Z",
     "start_time": "2019-08-17T21:04:05.926Z"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn\n",
    "for i in range(N):\n",
    "    grid = seaborn.lineplot(x=range(M+2) ,y=scores['logloss'][i,:])\n",
    "    grid.set(xscale=\"linear\", yscale=\"log\")\n",
    "plt.show()\n",
    "for i in range(N):\n",
    "    grid = seaborn.lineplot(x=range(M+2) ,y=scores['AOC'][i,:])\n",
    "    grid.set(xscale=\"linear\", yscale=\"log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-29T20:04:22.014608Z",
     "start_time": "2019-06-29T20:04:21.962258Z"
    }
   },
   "source": [
    "It seems to be more worse on logloss but same on other metrics relating to class assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-29T19:47:04.003749Z",
     "start_time": "2019-07-29T19:47:03.951521Z"
    }
   },
   "source": [
    "Worse on logloss and the same on accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the third time in a row always the same 2 datapoints. It seems no matter how much we augment these two can not predicted in the right class.  I wondr if they are mis-labeled.  If we take them out, then train will predict test 100% accuracy. Hmm!, I wonder what logloss score would be?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seemed to lower the logloss more which means the learner is better at assigning correct class probabilities. Note,isotonic in ``CalibratedClassifierCV`` is similar to clipping both ends of predicted class probability distributions. Let us augment the train dataset again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still causing logloss to go down. Let us stop there on this toy dataset and see how we do on a larger and noisier dataset. \n",
    "\n",
    "Now we cleanup all the object instances we made and no longer need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-17T21:04:14.286980Z",
     "start_time": "2019-08-17T21:04:05.929Z"
    }
   },
   "outputs": [],
   "source": [
    "del inputer\n",
    "del splitter\n",
    "del class_balancer\n",
    "del augmenter\n",
    "del learner\n",
    "del yeast3\n",
    "del train\n",
    "del test\n",
    "del augment"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "notify_time": "0",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "207.11956787109375px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
