{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Part 2 - More  Uncommon Data Cleaners for your Machine or Deep Learning Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## import local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-12T14:39:34.603453Z",
     "start_time": "2019-12-12T14:39:30.223864Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# packages in environment at /Users/brucecottman/anaconda3/envs/paso:\r\n",
      "#\r\n",
      "# Name                    Version                   Build  Channel\r\n",
      "_ipyw_jlab_nb_ext_conf    0.1.0                    py37_0  \r\n",
      "absl-py                   0.7.0                    pypi_0    pypi\r\n",
      "alabaster                 0.7.12                   py37_0  \r\n",
      "anaconda-client           1.7.2                    py37_0  \r\n",
      "anaconda-navigator        1.9.6                    py37_0  \r\n",
      "anaconda-project          0.8.2                    py37_0  \r\n",
      "ansimarkup                1.4.0                    pypi_0    pypi\r\n",
      "appnope                   0.1.0                    py37_0  \r\n",
      "appscript                 1.0.1            py37h1de35cc_1  \r\n",
      "asn1crypto                0.24.0                   py37_0  \r\n",
      "astor                     0.7.1                    pypi_0    pypi\r\n",
      "astroid                   2.1.0                    py37_0  \r\n",
      "astropy                   3.1              py37h1de35cc_0  \r\n",
      "astunparse                1.6.2                    pypi_0    pypi\r\n",
      "atomicwrites              1.2.1                    py37_0  \r\n",
      "attrdict                  2.0.1                    pypi_0    pypi\r\n",
      "attrs                     18.2.0           py37h28b3542_0  \r\n",
      "babel                     2.6.0                    py37_0  \r\n",
      "backcall                  0.1.0                    py37_0  \r\n",
      "backports                 1.0                      py37_1  \r\n",
      "backports.os              0.1.1                    py37_0  \r\n",
      "backports.shutil_get_terminal_size 1.0.0                    py37_2  \r\n",
      "beautifulsoup4            4.6.3                    py37_0  \r\n",
      "better-exceptions-fork    0.2.1.post6              pypi_0    pypi\r\n",
      "bitarray                  0.8.3            py37h1de35cc_0  \r\n",
      "bkcharts                  0.2                      py37_0  \r\n",
      "blas                      1.0                         mkl  \r\n",
      "blaze                     0.11.3                   py37_0  \r\n",
      "bleach                    3.0.2                    py37_0  \r\n",
      "blosc                     1.14.4               hd9629dc_0  \r\n",
      "bokeh                     1.0.4                    py37_0  \r\n",
      "boto                      2.49.0                   py37_0  \r\n",
      "boto3                     1.9.148                  pypi_0    pypi\r\n",
      "botocore                  1.12.148                 pypi_0    pypi\r\n",
      "bottleneck                1.2.1            py37h1d22016_1  \r\n",
      "bzip2                     1.0.6                h1de35cc_5  \r\n",
      "ca-certificates           2019.1.23                     0  \r\n",
      "cairo                     1.14.12              hc4e6be7_4  \r\n",
      "catboost                  0.12.2                   pypi_0    pypi\r\n",
      "category-encoders         2.0.0                    pypi_0    pypi\r\n",
      "certifi                   2019.3.9                 py37_0  \r\n",
      "cffi                      1.11.5           py37h6174b99_1  \r\n",
      "chardet                   3.0.4                    py37_1  \r\n",
      "click                     7.0                      py37_0  \r\n",
      "cloudpickle               0.6.1                    py37_0  \r\n",
      "clyent                    1.2.2                    py37_1  \r\n",
      "colorama                  0.4.1                    py37_0  \r\n",
      "colour                    0.1.5                    pypi_0    pypi\r\n",
      "conda-verify              3.1.1                    py37_0  \r\n",
      "confuse                   1.0.0                    pypi_0    pypi\r\n",
      "contextlib2               0.5.5                    py37_0  \r\n",
      "coverage                  4.5.2                    pypi_0    pypi\r\n",
      "cryptography              2.4.2            py37ha12b0ac_0  \r\n",
      "curl                      7.63.0            ha441bb4_1000  \r\n",
      "cvxpy                     1.0.18                   pypi_0    pypi\r\n",
      "cycler                    0.10.0                   py37_0  \r\n",
      "cymem                     2.0.2                    pypi_0    pypi\r\n",
      "cython                    0.29.2           py37h0a44026_0  \r\n",
      "cytoolz                   0.9.0.1          py37h1de35cc_1  \r\n",
      "dask                      1.0.0                    py37_0  \r\n",
      "dask-core                 1.0.0                    py37_0  \r\n",
      "datashape                 0.5.4                    py37_1  \r\n",
      "dbus                      1.13.2               h760590f_1  \r\n",
      "decorator                 4.3.0                    py37_0  \r\n",
      "defusedxml                0.5.0                    py37_1  \r\n",
      "dill                      0.2.9                    pypi_0    pypi\r\n",
      "distributed               1.25.1                   py37_0  \r\n",
      "docker                    4.0.2                    pypi_0    pypi\r\n",
      "docutils                  0.14                     py37_0  \r\n",
      "ecos                      2.0.7.post1              pypi_0    pypi\r\n",
      "entrypoints               0.2.3                    py37_2  \r\n",
      "enum34                    1.1.6                    pypi_0    pypi\r\n",
      "et_xmlfile                1.0.1                    py37_0  \r\n",
      "expat                     2.2.6                h0a44026_0  \r\n",
      "fancyimpute               0.4.2                    pypi_0    pypi\r\n",
      "fastai                    1.0.45                   pypi_0    pypi\r\n",
      "fastcache                 1.0.2            py37h1de35cc_2  \r\n",
      "fastprogress              0.1.19                   pypi_0    pypi\r\n",
      "filelock                  3.0.10                   py37_0  \r\n",
      "findspark                 1.3.0                    pypi_0    pypi\r\n",
      "flask                     1.0.2                    py37_1  \r\n",
      "flask-cors                3.0.7                    py37_0  \r\n",
      "flatbuffers               1.10                     pypi_0    pypi\r\n",
      "fontconfig                2.13.0               h5d5b041_1  \r\n",
      "freetype                  2.9.1                hb4e5f40_0  \r\n",
      "fribidi                   1.0.5                h1de35cc_0  \r\n",
      "funcsigs                  1.0.2                    pypi_0    pypi\r\n",
      "future                    0.17.1                   py37_0  \r\n",
      "gast                      0.2.2                    pypi_0    pypi\r\n",
      "geojson                   2.5.0                    pypi_0    pypi\r\n",
      "get_terminal_size         1.0.0                h7520d66_0  \r\n",
      "gettext                   0.19.8.1             h15daf44_3  \r\n",
      "gevent                    1.3.7            py37h1de35cc_1  \r\n",
      "glib                      2.56.2               hd9629dc_0  \r\n",
      "glob2                     0.6                      py37_1  \r\n",
      "gmp                       6.1.2                hb37e062_1  \r\n",
      "gmpy2                     2.0.8            py37h6ef4df4_2  \r\n",
      "graphite2                 1.3.13               h2098e52_0  \r\n",
      "graphviz                  2.40.1               hefbbd9a_2  \r\n",
      "greenlet                  0.4.15           py37h1de35cc_0  \r\n",
      "grpcio                    1.18.0                   pypi_0    pypi\r\n",
      "h5py                      2.8.0            py37h878fce3_3  \r\n",
      "harfbuzz                  1.8.8                hb8d4a28_0  \r\n",
      "hdf5                      1.10.2               hfa1e0ec_1  \r\n",
      "heapdict                  1.0.0                    py37_2  \r\n",
      "hpsklearn                 0.1.0                    pypi_0    pypi\r\n",
      "html5lib                  1.0.1                    py37_0  \r\n",
      "htmlmin                   0.1.12                   pypi_0    pypi\r\n",
      "hyperopt                  0.1.2                    pypi_0    pypi\r\n",
      "icu                       58.2                 h4b95b61_1  \r\n",
      "idna                      2.8                      py37_0  \r\n",
      "imageio                   2.4.1                    py37_0  \r",
      "\r\n",
      "imagesize                 1.1.0                    py37_0  \r\n",
      "imbalanced-learn          0.4.3                    pypi_0    pypi\r\n",
      "importlib_metadata        0.6                      py37_0  \r\n",
      "intel-openmp              2019.1                      144  \r\n",
      "ipykernel                 5.1.0            py37h39e3cac_0  \r\n",
      "ipython                   7.2.0            py37h39e3cac_0  \r\n",
      "ipython_genutils          0.2.0                    py37_0  \r\n",
      "ipywidgets                7.4.2                    py37_0  \r\n",
      "isort                     4.3.4                    py37_0  \r\n",
      "isoweek                   1.3.3                    pypi_0    pypi\r\n",
      "itsdangerous              1.1.0                    py37_0  \r\n",
      "jbig                      2.1                  h4d881f8_0  \r\n",
      "jdcal                     1.4                      py37_0  \r\n",
      "jedi                      0.13.2                   py37_0  \r\n",
      "jinja2                    2.10                     py37_0  \r\n",
      "jmespath                  0.9.4                    pypi_0    pypi\r\n",
      "joblib                    0.13.2                   pypi_0    pypi\r\n",
      "jpeg                      9b                   he5867d9_2  \r\n",
      "jsonschema                2.6.0                    py37_0  \r\n",
      "jupyter                   1.0.0                    py37_7  \r\n",
      "jupyter-contrib-core      0.3.3                    pypi_0    pypi\r\n",
      "jupyter-contrib-nbextensions 0.5.1                    pypi_0    pypi\r\n",
      "jupyter-highlight-selected-word 0.2.0                    pypi_0    pypi\r\n",
      "jupyter-latex-envs        1.4.6                    pypi_0    pypi\r\n",
      "jupyter-nbextensions-configurator 0.4.1                    pypi_0    pypi\r\n",
      "jupyter-notebook-gist     0.5.0                    pypi_0    pypi\r\n",
      "jupyter_client            5.2.4                    py37_0  \r\n",
      "jupyter_console           6.0.0                    py37_0  \r\n",
      "jupyter_core              4.4.0                    py37_0  \r\n",
      "jupyterlab                0.35.3                   py37_0  \r\n",
      "jupyterlab_server         0.2.0                    py37_0  \r\n",
      "keras                     2.2.4                    pypi_0    pypi\r\n",
      "keras-applications        1.0.7                    pypi_0    pypi\r\n",
      "keras-preprocessing       1.0.9                    pypi_0    pypi\r\n",
      "keyring                   17.0.0                   py37_0  \r\n",
      "kiwisolver                1.0.1            py37h0a44026_0  \r\n",
      "knnimpute                 0.1.0                    pypi_0    pypi\r\n",
      "krb5                      1.16.1               hddcf347_7  \r\n",
      "lazy-object-proxy         1.3.1            py37h1de35cc_2  \r\n",
      "libarchive                3.3.3                h786848e_5  \r\n",
      "libcurl                   7.63.0            h051b688_1000  \r\n",
      "libcxx                    4.0.1                hcfea43d_1  \r\n",
      "libcxxabi                 4.0.1                hcfea43d_1  \r\n",
      "libedit                   3.1.20170329         hb402a30_2  \r\n",
      "libffi                    3.2.1                h475c297_4  \r\n",
      "libgfortran               3.0.1                h93005f0_2  \r\n",
      "libiconv                  1.15                 hdd342a3_7  \r\n",
      "liblief                   0.9.0                h2a1bed3_0  \r\n",
      "libpng                    1.6.35               ha441bb4_0  \r\n",
      "libsodium                 1.0.16               h3efe00b_0  \r\n",
      "libssh2                   1.8.0                ha12b0ac_4  \r\n",
      "libtiff                   4.0.9                hcb84e12_2  \r\n",
      "libxml2                   2.9.8                hab757c2_1  \r\n",
      "libxslt                   1.1.32               hb819dd2_0  \r\n",
      "lightgbm                  2.2.3                    pypi_0    pypi\r\n",
      "llvm-openmp               4.0.1                hcfea43d_1  \r\n",
      "llvmlite                  0.26.0           py37h8c7ce04_0  \r\n",
      "locket                    0.2.0                    py37_1  \r\n",
      "loguru                    0.2.5                    pypi_0    pypi\r\n",
      "lxml                      4.2.5            py37hef8c89e_0  \r\n",
      "lz4-c                     1.8.1.2              h1de35cc_0  \r\n",
      "lzo                       2.10                 h362108e_2  \r\n",
      "markdown                  3.0.1                    pypi_0    pypi\r\n",
      "markupsafe                1.1.0            py37h1de35cc_0  \r\n",
      "matplotlib                3.0.2            py37h54f8f79_0  \r\n",
      "mccabe                    0.6.1                    py37_1  \r\n",
      "missingno                 0.4.2                    pypi_0    pypi\r\n",
      "mistune                   0.8.4            py37h1de35cc_0  \r\n",
      "mkl                       2019.1                      144  \r\n",
      "mkl-service               1.1.2            py37hfbe908c_5  \r\n",
      "mkl_fft                   1.0.6            py37h27c97d8_0  \r\n",
      "mkl_random                1.0.2            py37h27c97d8_0  \r\n",
      "mock                      2.0.0                    pypi_0    pypi\r\n",
      "modin                     0.4.0                    pypi_0    pypi\r\n",
      "more-itertools            4.3.0                    py37_0  \r\n",
      "mpc                       1.1.0                h6ef4df4_1  \r\n",
      "mpfr                      4.0.1                h3018a27_3  \r\n",
      "mpld3                     0.3                      pypi_0    pypi\r\n",
      "mpmath                    1.1.0                    py37_0  \r\n",
      "msgpack-numpy             0.4.3.2                  pypi_0    pypi\r\n",
      "msgpack-python            0.5.6            py37h04f5b5a_1  \r\n",
      "multipledispatch          0.6.0                    py37_0  \r\n",
      "multiprocess              0.70.7                   pypi_0    pypi\r\n",
      "murmurhash                1.0.1                    pypi_0    pypi\r\n",
      "navigator-updater         0.2.1                    py37_0  \r\n",
      "nbconvert                 5.4.1                    pypi_0    pypi\r\n",
      "nbformat                  4.4.0                    py37_0  \r\n",
      "nbsphinx                  0.4.2                    pypi_0    pypi\r\n",
      "ncurses                   6.1                  h0a44026_1  \r\n",
      "networkx                  2.2                      py37_1  \r\n",
      "ninja                     1.8.2            py37h04f5b5a_1  \r\n",
      "nltk                      3.4                      py37_1  \r\n",
      "nose                      1.3.7                    py37_2  \r\n",
      "notebook                  5.7.4                    py37_0  \r\n",
      "np-utils                  0.5.9.0                  pypi_0    pypi\r\n",
      "numba                     0.41.0           py37h6440ff4_0  \r\n",
      "numexpr                   2.6.8            py37h7413580_0  \r\n",
      "numpy                     1.15.0                   pypi_0    pypi\r\n",
      "numpydoc                  0.8.0                    py37_0  \r\n",
      "nvidia-ml-py3             7.352.0                  pypi_0    pypi\r\n",
      "odo                       0.5.1                    py37_0  \r\n",
      "olefile                   0.46                     py37_0  \r\n",
      "openpyxl                  2.5.12                   py37_0  \r\n",
      "openssl                   1.1.1b               h1de35cc_1  \r\n",
      "osqp                      0.5.0                    pypi_0    pypi\r\n",
      "packaging                 18.0                     py37_0  \r\n",
      "pandas                    0.25.3                   pypi_0    pypi\r\n",
      "pandas-flavor             0.2.0                    pypi_0    pypi\r\n",
      "pandas-profiling          2.3.0                    pypi_0    pypi\r\n",
      "pandas-summary            0.0.6                    pypi_0    pypi\r\n",
      "pandoc                    1.19.2.1             ha5e8f32_1  \r\n",
      "pandocfilters             1.4.2                    py37_1  \r\n",
      "pango                     1.42.4               h060686c_0  \r\n",
      "parso                     0.3.1                    py37_0  \r\n",
      "partd                     0.3.9                    py37_0  \r\n",
      "path.py                   11.5.0                   py37_0  \r\n",
      "pathlib2                  2.3.3                    py37_0  \r\n",
      "patsy                     0.5.1                    py37_0  \r\n",
      "pbr                       5.1.2                    pypi_0    pypi\r\n",
      "pcre                      8.42                 h378b8a2_0  \r\n",
      "pep8                      1.7.1                    py37_0  \r\n",
      "pexpect                   4.6.0                    py37_0  \r\n",
      "phik                      0.9.8                    pypi_0    pypi\r\n",
      "pickleshare               0.7.5                    py37_0  \r\n",
      "pillow                    5.3.0            py37hb68e598_0  \r\n",
      "pip                       19.3.1                   pypi_0    pypi\r\n",
      "pixiedust                 1.1.17                   pypi_0    pypi\r\n",
      "pixman                    0.38.0               h1de35cc_0  \r\n",
      "pkginfo                   1.4.2                    py37_1  \r\n",
      "plac                      0.9.6                    pypi_0    pypi\r\n",
      "plotly                    3.6.1                    pypi_0    pypi\r\n",
      "pluggy                    0.8.0                    py37_0  \r\n",
      "ply                       3.11                     py37_0  \r\n",
      "preshed                   2.0.1                    pypi_0    pypi\r\n",
      "probscale                 0.2.3                    pypi_0    pypi\r\n",
      "prometheus_client         0.5.0                    py37_0  \r\n",
      "prompt_toolkit            2.0.7                    py37_0  \r\n",
      "protobuf                  3.6.1                    pypi_0    pypi\r\n",
      "psutil                    5.4.8            py37h1de35cc_0  \r\n",
      "ptyprocess                0.6.0                    py37_0  \r\n",
      "py                        1.7.0                    py37_0  \r\n",
      "py-lief                   0.9.0            py37hd4eaf27_0  \r\n",
      "py4j                      0.10.7                   pypi_0    pypi\r\n",
      "pyarrow                   0.12.0                   pypi_0    pypi\r\n",
      "pycodestyle               2.4.0                    py37_0  \r\n",
      "pycosat                   0.6.3            py37h1de35cc_0  \r\n",
      "pycparser                 2.19                     py37_0  \r\n",
      "pycrypto                  2.6.1            py37h1de35cc_9  \r\n",
      "pycurl                    7.43.0.2         py37ha12b0ac_0  \r\n",
      "pydataset                 0.2.0                    pypi_0    pypi\r\n",
      "pydot                     1.3.0                    py37_1  \r\n",
      "pydot-ng                  2.0.0                    pypi_0    pypi\r\n",
      "pyflakes                  2.0.0                    py37_0  \r\n",
      "pygments                  2.3.1                    py37_0  \r\n",
      "pylint                    2.2.2                    py37_0  \r\n",
      "pymongo                   3.9.0                    pypi_0    pypi\r\n",
      "pyodbc                    4.0.25           py37h0a44026_0  \r\n",
      "pyopenssl                 18.0.0                   py37_0  \r\n",
      "pyparsing                 2.3.0                    py37_0  \r\n",
      "pyqt                      5.9.2            py37h655552a_2  \r\n",
      "pysocks                   1.6.8                    py37_0  \r\n",
      "pyspark                   2.4.3                    pypi_0    pypi\r\n",
      "pytables                  3.4.4            py37h13cba08_0  \r\n",
      "pytest                    4.0.2                    py37_0  \r\n",
      "pytest-arraydiff          0.3              py37h39e3cac_0  \r\n",
      "pytest-astropy            0.5.0                    py37_0  \r\n",
      "pytest-doctestplus        0.2.0                    py37_0  \r\n",
      "pytest-openfiles          0.3.1                    py37_0  \r\n",
      "pytest-pylint             0.14.1                   pypi_0    pypi\r\n",
      "pytest-remotedata         0.3.1                    py37_0  \r\n",
      "python                    3.7.1                haf84260_7  \r\n",
      "python-dateutil           2.7.5                    py37_0  \r\n",
      "python-libarchive-c       2.8                      py37_6  \r\n",
      "python.app                2                        py37_9  \r\n",
      "pytorch                   1.0.1                   py3.7_2    pytorch\r\n",
      "pytz                      2018.7                   py37_0  \r\n",
      "pywavelets                1.0.1            py37h1d22016_0  \r\n",
      "pyyaml                    3.13             py37h1de35cc_0  \r\n",
      "pyzmq                     17.1.2           py37h1de35cc_0  \r\n",
      "qt                        5.9.7                h468cd18_1  \r\n",
      "qtawesome                 0.5.3                    py37_0  \r\n",
      "qtconsole                 4.4.3                    py37_0  \r\n",
      "qtpy                      1.5.2                    py37_0  \r\n",
      "ray                       0.6.2                    pypi_0    pypi\r\n",
      "readline                  7.0                  h1de35cc_5  \r\n",
      "redis                     3.2.1                    pypi_0    pypi\r\n",
      "regex                     2018.1.10                pypi_0    pypi\r\n",
      "requests                  2.21.0                   py37_0  \r\n",
      "retrying                  1.3.3                    pypi_0    pypi\r\n",
      "rope                      0.11.0                   py37_0  \r\n",
      "ruamel_yaml               0.15.46          py37h1de35cc_0  \r\n",
      "s3fs                      0.2.1                    pypi_0    pypi\r\n",
      "s3transfer                0.2.0                    pypi_0    pypi\r\n",
      "scikit-image              0.14.1           py37h0a44026_0  \r\n",
      "scikit-learn              0.20.1           py37h27c97d8_0  \r\n",
      "scipy                     1.1.0            py37h1410ff5_2  \r\n",
      "scs                       2.0.2                    pypi_0    pypi\r\n",
      "seaborn                   0.9.0                    py37_0  \r\n",
      "send2trash                1.5.0                    py37_0  \r\n",
      "setuptools                40.6.3                   py37_0  \r\n",
      "simplegeneric             0.8.1                    py37_2  \r\n",
      "singledispatch            3.4.0.3                  py37_0  \r\n",
      "sip                       4.19.8           py37h0a44026_0  \r\n",
      "six                       1.12.0                   py37_0  \r\n",
      "sklearn                   0.0                      pypi_0    pypi\r\n",
      "sklearn-pandas            1.8.0                    pypi_0    pypi\r\n",
      "snappy                    1.1.7                he62c110_3  \r\n",
      "snowballstemmer           1.2.1                    py37_0  \r\n",
      "sortedcollections         1.0.1                    py37_0  \r\n",
      "sortedcontainers          2.1.0                    py37_0  \r\n",
      "spacy                     2.0.18                   pypi_0    pypi\r\n",
      "sphinx                    1.8.2                    py37_0  \r\n",
      "sphinx-automodapi         0.10                     pypi_0    pypi\r\n",
      "sphinx-gallery            0.2.0                    pypi_0    pypi\r\n",
      "sphinx-rtd-theme          0.4.3                    pypi_0    pypi\r\n",
      "sphinxcontrib             1.0                      py37_1  \r\n",
      "sphinxcontrib-websupport  1.1.0                    py37_1  \r\n",
      "spyder                    3.3.2                    py37_0  \r\n",
      "spyder-kernels            0.3.0                    py37_0  \r\n",
      "sqlalchemy                1.2.15           py37h1de35cc_0  \r\n",
      "sqlite                    3.26.0               ha441bb4_0  \r\n",
      "statsmodels               0.9.0            py37h1d22016_0  \r\n",
      "style                     1.1.0                    pypi_0    pypi\r\n",
      "sympy                     1.3                      py37_0  \r\n",
      "tblib                     1.3.2                    py37_0  \r\n",
      "tensorboard               1.12.2                   pypi_0    pypi\r\n",
      "tensorflow                1.13.0rc2                pypi_0    pypi\r\n",
      "tensorflow-estimator      1.13.0rc0                pypi_0    pypi\r\n",
      "termcolor                 1.1.0                    pypi_0    pypi\r\n",
      "terminado                 0.8.1                    py37_1  \r\n",
      "testpath                  0.4.2                    py37_0  \r\n",
      "thinc                     6.12.1                   pypi_0    pypi\r\n",
      "tk                        8.6.8                ha441bb4_0  \r\n",
      "toolz                     0.9.0                    py37_0  \r\n",
      "torchvision               0.2.1                      py_2    pytorch\r\n",
      "tornado                   5.1.1            py37h1de35cc_0  \r\n",
      "tqdm                      4.28.1           py37h28b3542_0  \r\n",
      "traitlets                 4.3.2                    py37_0  \r\n",
      "typing                    3.6.6                    pypi_0    pypi\r\n",
      "ujson                     1.35                     pypi_0    pypi\r\n",
      "unicodecsv                0.14.1                   py37_0  \r\n",
      "unidecode                 1.1.1                    pypi_0    pypi\r\n",
      "unixodbc                  2.3.7                h1de35cc_0  \r\n",
      "update                    0.0.1                    pypi_0    pypi\r\n",
      "urllib3                   1.24.1                   py37_0  \r\n",
      "wand                      0.5.1                    pypi_0    pypi\r\n",
      "wcwidth                   0.1.7                    py37_0  \r\n",
      "webencodings              0.5.1                    py37_1  \r\n",
      "websocket-client          0.56.0                   pypi_0    pypi\r\n",
      "werkzeug                  0.14.1                   py37_0  \r\n",
      "wheel                     0.32.3                   py37_0  \r\n",
      "widgetsnbextension        3.4.2                    py37_0  \r\n",
      "wrapt                     1.10.11          py37h1de35cc_2  \r\n",
      "wurlitzer                 1.0.2                    py37_0  \r\n",
      "xarray                    0.14.0                   pypi_0    pypi\r\n",
      "xgboost                   0.90                     pypi_0    pypi\r\n",
      "xlrd                      1.2.0                    py37_0  \r\n",
      "xlsxwriter                1.1.2                    py37_0  \r\n",
      "xlwings                   0.15.1                   py37_0  \r\n",
      "xlwt                      1.3.0                    py37_0  \r\n",
      "xz                        5.2.4                h1de35cc_4  \r\n",
      "yaml                      0.1.7                hc338f04_2  \r\n",
      "zeromq                    4.2.5                h0a44026_1  \r\n",
      "zict                      0.1.3                    py37_0  \r\n",
      "zlib                      1.2.11               h1de35cc_3  \r\n",
      "zstd                      1.3.7                h5bba6e5_0  \r\n"
     ]
    }
   ],
   "source": [
    "!conda list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-12T14:39:34.625913Z",
     "start_time": "2019-12-12T14:39:34.606666Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/brucecottman/Documents/PROJECTS/paso'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "__file__ = !cd .. ;pwd\n",
    "__file__ = __file__[0]\n",
    "__file__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-12T14:39:34.632901Z",
     "start_time": "2019-12-12T14:39:34.627980Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/brucecottman/Documents/PROJECTS/paso/lessons',\n",
       " '/Users/brucecottman/anaconda3/envs/paso/lib/python37.zip',\n",
       " '/Users/brucecottman/anaconda3/envs/paso/lib/python3.7',\n",
       " '/Users/brucecottman/anaconda3/envs/paso/lib/python3.7/lib-dynload',\n",
       " '',\n",
       " '/Users/brucecottman/.local/lib/python3.7/site-packages',\n",
       " '/Users/brucecottman/anaconda3/envs/paso/lib/python3.7/site-packages',\n",
       " '/Users/brucecottman/anaconda3/envs/paso/lib/python3.7/site-packages/aeosa',\n",
       " '/Users/brucecottman/anaconda3/envs/paso/lib/python3.7/site-packages/IPython/extensions',\n",
       " '/Users/brucecottman/.ipython',\n",
       " '/Users/brucecottman/Documents/PROJECTS/paso']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "from random import random\n",
    "sys.path.append(__file__)\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-12T14:39:34.641748Z",
     "start_time": "2019-12-12T14:39:34.636541Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/brucecottman/Documents/PROJECTS/paso/lessons',\n",
       " '/Users/brucecottman/anaconda3/envs/paso/lib/python37.zip',\n",
       " '/Users/brucecottman/anaconda3/envs/paso/lib/python3.7',\n",
       " '/Users/brucecottman/anaconda3/envs/paso/lib/python3.7/lib-dynload',\n",
       " '',\n",
       " '/Users/brucecottman/.local/lib/python3.7/site-packages',\n",
       " '/Users/brucecottman/anaconda3/envs/paso/lib/python3.7/site-packages',\n",
       " '/Users/brucecottman/anaconda3/envs/paso/lib/python3.7/site-packages/aeosa',\n",
       " '/Users/brucecottman/anaconda3/envs/paso/lib/python3.7/site-packages/IPython/extensions',\n",
       " '/Users/brucecottman/.ipython',\n",
       " '/Users/brucecottman/Documents/PROJECTS/paso',\n",
       " '/Users/brucecottman/Documents/PROJECTS/paso']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.path.append(__file__)\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-12T14:39:35.561920Z",
     "start_time": "2019-12-12T14:39:34.644948Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from random import random\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas_summary import DataFrameSummary\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import multiprocessing\n",
    "OMP_NUM_THREADS=1\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import cm\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "color = sns.color_palette()\n",
    "sns.set(rc={'figure.figsize':(6,4)})\n",
    "from loguru import logger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Executive Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Part 2, **Part 2 - More  Uncommon Data Cleaners for your Machine or Deep Learning Project**,  I will cover type and format transformative data cleaners.\n",
    "\n",
    "\n",
    "Almost all **paso**, including all the functions discussed here, require that **paso** data\n",
    "cleaning steps (such as removal of Null and NA values)\n",
    "has been done previous their use.\n",
    "\n",
    "These Data Cleaners are detailed in the lesson [Part 1 - Uncommon Data Cleaners for your Real-World Machine Learning Projects](https://github.com/bcottman/paso/blob/master/lessons/lesson-2.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Background Story"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "In our previous projects, we found ourselves spending the majority of our  time on cleaning the data with very similar or slightly different data cleaners.\n",
    "\n",
    "On the first project, we overspent quite a bit in  time in data cleaning development. So much so, that at the start of the 2nd project, project management had divided data cleaning into three categories: same, less than 33% different, and greater than 33% different. \n",
    "\n",
    "These categories were defined for two major reasons:\n",
    "- As a team we were able, as data cleaner needs were identified, to eliminate a lot of \"recode the wheel\" and add to our data cleaners package the greater than 33% different category.\n",
    "- Our development time estimations became more precise.\n",
    "\n",
    "After 2 and a half years, we are on our 6th project and find that, so far, that less than 1 out of 10 data cleaners fall into the third, more developer-time expensive, category. More importantly, we can now spend the majority of our time on finding a good-enough approach to the machine learning (and sometimes deep learning) solution.\n",
    "\n",
    "Your experience may be different, as my current domain is fixed-income financial data for asset-allocation, balancing, trends and risks. (Ok, yes, some other really obscure stuff that I won't mention or use here.)\n",
    "\n",
    "Now you may ask why I am telling this story. Because.. as we went down this path, I evolved from a machine learning scientist to a software architect and software engineer. \n",
    "\n",
    "I now get brought in to fix a in-production services as well as accomplish initial architecture design work and code development. I enjoy going from development to production. Sometimes I get to write and share some of our accomplishments.\n",
    "\n",
    "I sincerely hope you are able to use some of our work. All code, for functions used here, can be found at [https://github.com/bcottman/paso/toutil.py](https://github.com/bcottman/paso/toutil.py)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Enough story already, what can you show me!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The use of different combinations of cleaning strategies (pipelines) is an important goal of **paso**.\n",
    "\n",
    "Discussion will be divided into the following major segments:\n",
    "- First we create dataset we can clean and change. \n",
    "- Following this,  each cleaner is demonstrated by acting on the reated   dataset.\n",
    "- Then we show an invocation capability that mixes well with pipelines: chaining off the pandas data frame. This is familiar to R development model. We find it much easier to review code review than  sklearn pipelines. We would even argue that chaining is easier than traditional pipelining to understand.\n",
    "- Finally, we summarize paso's data cleaners and what we have planned for future articles and paso releases.\n",
    "\n",
    "The code for this lesson is given in [here](https://github.com/bcottman/paso/blob/master/lessons/) and [here](https://github.com/bcottman/paso/blob/master/paso/pre/toutil.py) files. The best way to get the entire paso package is to git clone the base.  ``pip``will not work as there are text-based files (descriptions), "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T21:51:40.186467Z",
     "start_time": "2019-11-20T21:51:39.881649Z"
    }
   },
   "source": [
    "## to_util: to_DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    paso.pre.toutil.toDataFrame(X: pd.DataFrame,\n",
    "        columns: List = None, \n",
    "        inplace: bool = True, \n",
    "        verbose: bool = True) \n",
    "        -> pd.DataFrame:\n",
    "        \n",
    "    Parameters:\n",
    "        X: DataFrame\n",
    "            Attempt to convert python datatype argument into pandas ataframe.\n",
    "\n",
    "        columns:     \n",
    "            The column names to  be used for new DataFrame. If number of column names given is less than number of column names needed, then they will generared as c_0...c_(n-1), where n is the number of missing column names.\n",
    "\n",
    "        verbose: default: True) Logging is on.\n",
    "\n",
    "        Returns: DataFrame\n",
    "         \n",
    "Code was based on `` willmcginnis's convert_input()``."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**paso** is a package in which all function and methods require a **pandas** DataFrame.\n",
    "\n",
    "Since **paso** functions and methods consume only **pandas** dataframes, we need a function to transform various python data-types and while also delivering **paso's** basic services. This function is ``paso.to_util.toDataFrame``. \n",
    "\n",
    "This function is the exception to \"**paso** first argument is a DataFrame \" rule, because it transforms a 1-D or 2-D list, tuple, csr_matrix, numpy array, or 1d **pandas** Series  into a  **pandas** DataFrame.\n",
    "\n",
    "You also have ``paso.to_util.isDataFrame(X) -> bool`` to check if the object is or is not a ``pandas.DataFrame``.\n",
    "\n",
    "Now you can use the method ``pandas.DataFrame``, if you don't require **paso's** basic services, such as logging and caching. I would recommend that you not do this, but you have the un-pythonic choice to do so."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A good practice is to make your dataset of type ``DataFrame`` at the start of your pipeline. Changes by the **paso** function will be kept in the DataFrame's change of state (``inplace=True``). This will happen\n",
    "though-out the pipeline of your experimental run to maximize\n",
    "speed of completion and minimize memory usage. \n",
    "\n",
    "If you need to refer to the original DataFrame, then you can do something similar to this:\n",
    "\n",
    "    <dataset_name>_original = <dataset_name>.copy()\n",
    "    \n",
    "However, you should be warned that keeping the original is going to take memory.  Almost always you input the original from a local file or non-local file addressed by URL.  \n",
    "\n",
    "It is up-to you to keep around a copy of the original dataset. Upon looking over your approach and goal(s), you will probably find you do not need to a copy of the original dataset.\n",
    "\n",
    "You can see the size of any object in bytes with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-12T14:39:35.605777Z",
     "start_time": "2019-12-12T14:39:35.563932Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sys import getsizeof\n",
    "getsizeof(pd.DataFrame())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows that an empty DataFrame has a size of 24 bytes.\n",
    "\n",
    "Now, create a artificial dataset, ``df_of_ints``, a numpy array of `int`s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-12T18:29:08.169288Z",
     "start_time": "2019-12-12T18:29:08.083798Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-12 13:29:08.164 | INFO     | paso.pre.toutil:toDataFrame:112 - toDataFrame  with \n",
      "column names: Index(['c_0', 'c_1', 'c_2', 'c_3', 'c_4', 'c_5'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "from paso.base import raise_PasoError  \n",
    "from paso.pre.toutil import toDataFrame\n",
    "arr = np.ndarray(shape=(1000000,6), dtype=int, order='F')\n",
    "df_of_ints = toDataFrame(arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-21T18:09:12.089455Z",
     "start_time": "2019-11-21T18:09:12.030954Z"
    }
   },
   "source": [
    "` toDataFrame(arr, columns=['a','b'])`\n",
    "\n",
    " can specify first two column names,for the new DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-12T18:29:22.988233Z",
     "start_time": "2019-12-12T18:29:22.907991Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-12 13:29:22.981 | INFO     | paso.pre.toutil:toDataFrame:112 - toDataFrame  with \n",
      "column names: Index(['a', 'b', 'c_2', 'c_3', 'c_4', 'c_5'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1000000, 6)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_of_ints = toDataFrame(arr, columns=['a','b'])\n",
    "df_of_ints.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the first two column names were given and ``toDataFrame``detected this and created the next 4 that were needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time we invoke ``toDataFrame`` while keeping **paso** logging off. Logging is only turned off for the scope of the function invoked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-12T18:29:30.207705Z",
     "start_time": "2019-12-12T18:29:30.132298Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['X', 'yyyyyy', 'c_2', 'c_3', 'c_4', 'c_5'], dtype='object')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_of_ints = toDataFrame(arr, columns=['X','yyyyyy'],verbose =False)\n",
    "df_of_ints.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## to_util: toCategory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "     paso.pre.toutil.toCategory(\n",
    "        X: pd.DataFrame,\n",
    "        bool_: bool = True,\n",
    "        int_: bool = True,\n",
    "        object_: str = True,\n",
    "        inplace: bool = True,\n",
    "        verbose: bool = True,\n",
    "    ) -> pd.DataFrame:\n",
    "    \n",
    "    Parameters:\n",
    "        X: dataFrame\n",
    "\n",
    "        bool_: default :True\n",
    "            If True will convert to category type.\n",
    "\n",
    "        int_: default: True\n",
    "            If True will convert to category type.\n",
    "\n",
    "        object_: default: True\n",
    "            If True will convert to category type.\n",
    "\n",
    "        inplace: default: True\n",
    "            True: change DataFrame arg in-place\"\n",
    "\n",
    "            False:  return new resulting DataFrame\n",
    "            \n",
    "        verbose: default: True Logging is on.\n",
    "    \n",
    "    Returns: resulting DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function transforms any boolean, object or integer values of \n",
    "of a pandas DataFrame to category type values.\n",
    "\n",
    "The exception is continuous (``float`` or ``datetime``) values which are returned un-transformed. \n",
    "\n",
    "If you want to convert continuous or datetime types to\n",
    "category then use ``ContinuoustoCategory`` or ``DatetimetoComponents``\n",
    "before **paso** (step) ``toCategory``.\n",
    "\n",
    "Note:\n",
    "Assumes **paso**  data\n",
    "cleaning steps (such as removal of Null and NA values) have\n",
    "been done previous to this step.\n",
    "\n",
    "``datetime`` features should call ``toDatetimeComponents()``\n",
    "previous to this step so that ``datetime`` components (which are of type\n",
    "``np.number``) can be converted to ``category``.\n",
    "\n",
    "The default\n",
    "behavior of this step is NOT to convert ``datetime`` to ``category``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-12T18:36:58.827238Z",
     "start_time": "2019-12-12T18:36:58.641913Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-12 13:36:58.748 | INFO     | paso.pre.toutil:toCategory:197 - toCategory integer feature converted : X\n",
      "2019-12-12 13:36:58.768 | INFO     | paso.pre.toutil:toCategory:197 - toCategory integer feature converted : yyyyyy\n",
      "2019-12-12 13:36:58.786 | INFO     | paso.pre.toutil:toCategory:197 - toCategory integer feature converted : c_2\n",
      "2019-12-12 13:36:58.802 | INFO     | paso.pre.toutil:toCategory:197 - toCategory integer feature converted : c_3\n",
      "2019-12-12 13:36:58.814 | INFO     | paso.pre.toutil:toCategory:197 - toCategory integer feature converted : c_4\n",
      "2019-12-12 13:36:58.824 | INFO     | paso.pre.toutil:toCategory:197 - toCategory integer feature converted : c_5\n"
     ]
    }
   ],
   "source": [
    "from paso.base import raise_PasoError  \n",
    "from paso.pre.toutil import toCategory\n",
    "df_cat = toCategory(df_of_ints,inplace=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like ``df_of_ints`` is unchanged, which is what want in this case, `inplace=False`\n",
    "."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-12T14:39:37.092739Z",
     "start_time": "2019-12-12T14:39:37.032083Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "X         int64\n",
       "yyyyyy    int64\n",
       "c_2       int64\n",
       "c_3       int64\n",
       "c_4       int64\n",
       "c_5       int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_of_ints.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it looks like all values of ``df_of_ints`` are of type int converted to tpye category, `inplace=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-12T14:39:37.287816Z",
     "start_time": "2019-12-12T14:39:37.095150Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-12 09:39:37.193 | INFO     | paso.pre.toutil:toCategory:197 - toCategory integer feature converted : X\n",
      "2019-12-12 09:39:37.214 | INFO     | paso.pre.toutil:toCategory:197 - toCategory integer feature converted : yyyyyy\n",
      "2019-12-12 09:39:37.233 | INFO     | paso.pre.toutil:toCategory:197 - toCategory integer feature converted : c_2\n",
      "2019-12-12 09:39:37.251 | INFO     | paso.pre.toutil:toCategory:197 - toCategory integer feature converted : c_3\n",
      "2019-12-12 09:39:37.269 | INFO     | paso.pre.toutil:toCategory:197 - toCategory integer feature converted : c_4\n",
      "2019-12-12 09:39:37.282 | INFO     | paso.pre.toutil:toCategory:197 - toCategory integer feature converted : c_5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "X         category\n",
       "yyyyyy    category\n",
       "c_2       category\n",
       "c_3       category\n",
       "c_4       category\n",
       "c_5       category\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_of_ints.toCategory(inplace=True)\n",
    "df_of_ints.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chaining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am guessing some of the readers (not you) are a little bothered by ``df_of_ints.toCategory(inplace=True)``. If so, you will be more bothered by this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-12T14:39:37.476127Z",
     "start_time": "2019-12-12T14:39:37.289768Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-12 09:39:37.359 | INFO     | paso.pre.toutil:toDataFrame:112 - toDataFrame  with column names: Index(['a', 'b', 'c_2', 'c_3', 'c_4', 'c_5'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "a      category\n",
       "b      category\n",
       "c_2    category\n",
       "c_3    category\n",
       "c_4    category\n",
       "c_5    category\n",
       "dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toDataFrame(arr, columns=['a','b']).toCategory(verbose=False).dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are not bothered or even puzzled about this fuss, it is because you know that a DataFrame is a ``python`` class and you call methods off a class. You can even *chain* methods after a class or class instance.\n",
    "\n",
    "In this case, I *chained*  the two methods ``.toCategory().dtypes`` off the DataFame output by `toDataFrame`\n",
    ".\n",
    "\n",
    "All the metods of class ``Cleaners`` and functions of ``toutils.py``of **paso** require the 1st argument to be a\n",
    " DataFrame instance. This enables them to be methods of a DataFrame instance by using a decorator found in the package **pandas-flavor**.\n",
    " \n",
    "Chaining can make it very easy to understand, because operations are invoked left to right. That is the same way you read (English and many other languages).\n",
    "\n",
    "Some people prefer to chain instead of using **sklearn's Pipelines**.  You will notice how our chaining is slightly different in syntax than **sklearn's Pipeline** chaining.\n",
    "\n",
    "Our chaining is very close to the look-and-feel of ``R``.   We will use both invocation methods from now on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T17:45:58.820234Z",
     "start_time": "2019-11-06T17:45:58.736008Z"
    }
   },
   "source": [
    "## toutil: toDatetimeComponents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "     paso.pre.toutil.toDatetimeComponents(\n",
    "        X: pd.DataFrame,\n",
    "        drop: bool = True,\n",
    "        components: list = [],\n",
    "        prefix: bool = True,\n",
    "        inplace: bool = True,\n",
    "        verbose: bool = True) -> pd.DataFrame:\n",
    "        \n",
    "    Parameters:\n",
    "        \n",
    "        X: DataFrame\n",
    "\n",
    "        drop: default: True\n",
    "            If True then the datetime feature/column will be removed.\n",
    "\n",
    "        components:: default: []\n",
    "            list of column(feature) names for which datetime components\n",
    "            are created.\n",
    "\n",
    "        prefix: default: True\n",
    "            If True then the feature will be the prefix of the created datetime component fetures. The posfix will be _<component> to create the new feature column <feature>_<component>.\n",
    "\n",
    "            if False only first _PREFIX_LENGTH_ characters of feature string will be used to\n",
    "            create the new feature name/column <featurename[0:_PREFIX_LENGTH_]>_<component>.\n",
    "\n",
    "        components:list default:\n",
    "            ['Year', 'Month', 'Week', 'Day','Dayofweek'\n",
    "            , 'Dayofyear','Elapsed','Is_month_end'\n",
    "            , 'Is_month_start', 'Is_quarter_end'\n",
    "            , 'Is_quarter_start', 'Is_year_end', 'Is_year_start']\n",
    "\n",
    "            or set components to one or component names in a list\n",
    "            Must be components names from default list.\n",
    "            \n",
    "        inplace: default: True\n",
    "            True: change DataFrame arg in-place\"\n",
    "\n",
    "            False: return new resulting dataframe\n",
    "            \n",
    "        verbose: default: True Logging is on.\n",
    "    \n",
    "\n",
    "    Returns:DataFrame\n",
    "            toDatetimeComponents transformed into datetime feature components\n",
    "\n",
    "   Raises:\n",
    "   \n",
    "        ValueError: if any dt_features = [].\n",
    "\n",
    "        ValueError: if any feature has NA values.\n",
    "        \n",
    "if X[[dt_features]] is not of datetime type  (such as ``object`` type)\n",
    "then there **IS NO** attempt to coerce X[[dt_features]] to ``datetime`` type.\n",
    "\n",
    "It is best if raw data field\n",
    "is read/input in as ``datetime`` rather than ``object``. Another way, is to convert\n",
    "dataframe column using\n",
    "\n",
    "    X[feature] = pd.datetime(X[feature])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For many reasons, all resulting in better predictive power, you can break a ``datetime`` into ``int`` components.  You can go further and convert ``datetime`` ``int`` components into categorical-type components.\n",
    "\n",
    "Why would you want to this? Well it leads to an advanced encoding tactic, that is discussed in detail in the paper [Entity Embeddings of Categorical Variables ]( https://`arxiv.org/pdf/1604.06737.pdf) \n",
    "and [Entity Embeddings of Categorical Variables in Neural Networks](https://towardsdatascience.com/decoded-entity-embeddings-of-categorical-variables-in-neural-networks-1d2468311635a)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The latter article states:\n",
    "\n",
    "    \"Categorical variables are known to hide and mask lots of interesting information in a data set and many times they might even be the most important variables in a model. A good data scientist should be capable of handling such variables effectively and efficiently. If you are a smart data scientist, you’d hunt down the categorical variables in the data set, and dig out as much information as you can.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You probably see were this going. If I have some non-categorical features, such as column of ``datetimes``, I will need a function to turn datetime into categorical(s) feature(s). \n",
    "\n",
    "I  will cover how to use categorical features as embedding vectors in an upcoming article.\n",
    "\n",
    "You can see what datetime components are available with ``datetimeComponents``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-12T14:39:37.536753Z",
     "start_time": "2019-12-12T14:39:37.478379Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Year',\n",
       " 'Month',\n",
       " 'Week',\n",
       " 'Day',\n",
       " 'Dayofweek',\n",
       " 'Dayofyear',\n",
       " 'Elapsed',\n",
       " 'Is_month_end',\n",
       " 'Is_month_start',\n",
       " 'Is_quarter_end',\n",
       " 'Is_quarter_start',\n",
       " 'Is_year_end',\n",
       " 'Is_year_start']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from paso.pre.toutil import datetimeComponents\n",
    "datetimeComponents()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I first create dataset to can show what ``toDatetimeComponents  `` does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-12T14:39:37.854447Z",
     "start_time": "2019-12-12T14:39:37.539037Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-12 09:39:37.601 | INFO     | paso.pre.toutil:toDataFrame:112 - toDataFrame  with column names: Index(['c_0'], dtype='object')\n",
      "2019-12-12 09:39:37.609 | INFO     | paso.pre.toutil:toDatetimeComponents:346 - datetime feature component added: c_0_Year\n",
      "2019-12-12 09:39:37.614 | INFO     | paso.pre.toutil:toDatetimeComponents:346 - datetime feature component added: c_0_Month\n",
      "2019-12-12 09:39:37.621 | INFO     | paso.pre.toutil:toDatetimeComponents:346 - datetime feature component added: c_0_Week\n",
      "2019-12-12 09:39:37.627 | INFO     | paso.pre.toutil:toDatetimeComponents:346 - datetime feature component added: c_0_Day\n",
      "2019-12-12 09:39:37.633 | INFO     | paso.pre.toutil:toDatetimeComponents:346 - datetime feature component added: c_0_Dayofweek\n",
      "2019-12-12 09:39:37.640 | INFO     | paso.pre.toutil:toDatetimeComponents:346 - datetime feature component added: c_0_Dayofyear\n",
      "2019-12-12 09:39:37.794 | INFO     | paso.pre.toutil:toDatetimeComponents:346 - datetime feature component added: c_0_Elapsed\n",
      "2019-12-12 09:39:37.800 | INFO     | paso.pre.toutil:toDatetimeComponents:346 - datetime feature component added: c_0_Is_month_end\n",
      "2019-12-12 09:39:37.805 | INFO     | paso.pre.toutil:toDatetimeComponents:346 - datetime feature component added: c_0_Is_month_start\n",
      "2019-12-12 09:39:37.812 | INFO     | paso.pre.toutil:toDatetimeComponents:346 - datetime feature component added: c_0_Is_quarter_end\n",
      "2019-12-12 09:39:37.816 | INFO     | paso.pre.toutil:toDatetimeComponents:346 - datetime feature component added: c_0_Is_quarter_start\n",
      "2019-12-12 09:39:37.822 | INFO     | paso.pre.toutil:toDatetimeComponents:346 - datetime feature component added: c_0_Is_year_end\n",
      "2019-12-12 09:39:37.828 | INFO     | paso.pre.toutil:toDatetimeComponents:346 - datetime feature component added: c_0_Is_year_start\n",
      "2019-12-12 09:39:37.837 | INFO     | paso.pre.toutil:toDatetimeComponents:351 - datetime feature dropped: c_0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c_0_Year</th>\n",
       "      <th>c_0_Month</th>\n",
       "      <th>c_0_Week</th>\n",
       "      <th>c_0_Day</th>\n",
       "      <th>c_0_Dayofweek</th>\n",
       "      <th>c_0_Dayofyear</th>\n",
       "      <th>c_0_Elapsed</th>\n",
       "      <th>c_0_Is_month_end</th>\n",
       "      <th>c_0_Is_month_start</th>\n",
       "      <th>c_0_Is_quarter_end</th>\n",
       "      <th>c_0_Is_quarter_start</th>\n",
       "      <th>c_0_Is_year_end</th>\n",
       "      <th>c_0_Is_year_start</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1751</td>\n",
       "      <td>7</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>182</td>\n",
       "      <td>1694609792</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1751</td>\n",
       "      <td>7</td>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>183</td>\n",
       "      <td>1694696192</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   c_0_Year  c_0_Month  c_0_Week  c_0_Day  c_0_Dayofweek  c_0_Dayofyear  \\\n",
       "0      1751          7        26        1              3            182   \n",
       "1      1751          7        26        2              4            183   \n",
       "\n",
       "   c_0_Elapsed  c_0_Is_month_end  c_0_Is_month_start  c_0_Is_quarter_end  \\\n",
       "0   1694609792             False                True               False   \n",
       "1   1694696192             False               False               False   \n",
       "\n",
       "   c_0_Is_quarter_start  c_0_Is_year_end  c_0_Is_year_start  \n",
       "0                  True            False              False  \n",
       "1                 False            False              False  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "rc = 94598; cc = 1; acc =13\n",
    "darr = np.arange(datetime(1751,7,1),\n",
    "                 datetime(2010,7,1),\n",
    "                 timedelta(days=1)).reshape(rc,cc)\n",
    "\n",
    "#%debug\n",
    "from paso.pre.toutil import toDatetimeComponents\n",
    "#toDataFrame(darr,labels = [])\n",
    "toDataFrame(darr,columns = []).toDatetimeComponents(inplace=False).head(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, ``datetimeComponents`` transformed each datetime value into 13 ``int`` components. It then transformed those ``int`` types into ``category`` types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## toutil: toContinuousCategory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    def toContinuousCategory(\n",
    "        X: pd.DataFrame,\n",
    "        features:List=[],\n",
    "        drop: bool = True,\n",
    "        inplace: bool = True,\n",
    "        verbose: bool = True,\n",
    "        integer: bool = True,\n",
    "        floaty: bool = True,\n",
    "        quantile: bool = True,\n",
    "        nbin: int = 10,\n",
    "    ) -> pd.DataFrame:\n",
    "    \n",
    "    Parameters:\n",
    "        X:pd.DataFrame\n",
    "\n",
    "        drop: default:True\n",
    "            do not keep original features.\n",
    "\n",
    "        integer: default:True\n",
    "            set integer=False if not continuous and not to \n",
    "            transform into category.\n",
    "\n",
    "        floaty: default:True\n",
    "            set floaty=False if not continuous and not to \n",
    "            transform into category.\n",
    "\n",
    "        quantile: default: True\n",
    "            use quantile bin.\n",
    "            quantile is similar to v/(maxy-miny), works on any scale.\n",
    "            False, use fixed-width bin. miny,maxy arguments are ignored.\n",
    "\n",
    "        nbin:int (default: 10)\n",
    "\n",
    "    Returns: DataFrame\n",
    "\n",
    "    Raises:\n",
    "        TypeError('\"ContinuoustoCategory:inplace: requires boolean type.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``toContinuousCategory`` transforms any continuous float, or integer values of\n",
    "a pandas dataframe to category values by grouping into bins.\n",
    "\n",
    "Binning, also known as quantization is used for\n",
    "transforming continuous numeric features\n",
    "(``np.number`` type) into ``category`` type.\n",
    "\n",
    "Each bin represents a range of continuous numeric values.\n",
    "\n",
    "Specific strategies of binning data include fixed-width\n",
    "(``quantile=False``) and adaptive binning (``quantile = True``).\n",
    "\n",
    "No matter the type of the input dataset it  will be returned\n",
    "as ``DataFrame``. If you want to set the feature names, call ``toDataFrame`` before this function.\n",
    "\n",
    "Fixed-width bin, only works, WITHOUT SCALING, with datasets with multiple features for tree-based models such as CART, random forest, xgboost, lightgbm, catboost,etc. Namely linear, log, SVM, neural nets, etc. won't work correctly.\n",
    "\n",
    "**Statistical problems with linear binning.**\n",
    "\n",
    "Binning increases type I and type II error; (simple proof is that as number\n",
    "of bins approaches infinity then information loss approaches zero).\n",
    "In addition, changing the number of bins will alter the bin distrution shape,\n",
    "unless the distribution is uniformLY FLAT.\n",
    "\n",
    "**Quantile binning can only be used with a singular data set.**\n",
    "\n",
    "Transforming a Continuous featuree ino a Category feature based on percentiles (QUANTILES) is WRONG\n",
    "if you have a train and test data sets. Quantiles are based on the data set and will be different unless\n",
    "each data set distribution shape is the same. In the limit there are only two bins,\n",
    "then almost no relationship can be modeled. We are essentially doing a t-test.\n",
    "\n",
    "**if there are nonlinear or even nonmonotonic relationships between features**\n",
    "\n",
    "If you need linear binning, not quantile, use\n",
    "``quantile=False`` .\n",
    "\n",
    "**If you want Quantile-binning.**\n",
    "\n",
    "Despite the above warnings, your use case may require. quantile-binning.\n",
    "Quantile based binning is a faily good strategy to use for adaptive binning.\n",
    "Quantiles are specific values or cut-points which partition\n",
    "the continuous valued distribution of a feature into\n",
    "discrete contiguous bins or intervals. Thus, q-Quantiles\n",
    "partition a numeric attribute into q equal (percetage-width) partitions.\n",
    "\n",
    "Well-known examples of quantiles include the 2-Quantile ,median,\n",
    "divides the data distribution into two equal (percetage-width) bins, 4-Quantiles,\n",
    ",standard quartiles, 4 equal bins (percentage-width) and 10-Quantiles,\n",
    "deciles, 10 equal width (percentage-width) bins.\n",
    "\n",
    "You should note that the new features resulting from quantile-binning are appended with ``q``. While new features resulting from fixed-width-binning are appended with ``w``.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tranform continuous float features into category and drop the original columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-12T20:27:28.222278Z",
     "start_time": "2019-12-12T20:27:27.551002Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-12 15:27:27.638 | INFO     | paso.pre.toutil:toDataFrame:112 - toDataFrame  with \n",
      "column names: Index(['c_0', 'c_1', 'c_2', 'c_3', 'c_4', 'c_5'], dtype='object')\n",
      "2019-12-12 15:27:28.204 | INFO     | paso.pre.toutil:toContinuousCategory:533 - toContinuousCategory features:: Index(['c_0', 'c_1', 'c_2', 'c_3', 'c_4', 'c_5'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c_0q</th>\n",
       "      <th>c_1q</th>\n",
       "      <th>c_2q</th>\n",
       "      <th>c_3q</th>\n",
       "      <th>c_4q</th>\n",
       "      <th>c_5q</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(-0.001, 59999.94]</td>\n",
       "      <td>(0.099, 60000.04]</td>\n",
       "      <td>(0.199, 60000.14]</td>\n",
       "      <td>(0.299, 60000.24]</td>\n",
       "      <td>(0.399, 60000.34]</td>\n",
       "      <td>(0.499, 60000.44]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(-0.001, 59999.94]</td>\n",
       "      <td>(0.099, 60000.04]</td>\n",
       "      <td>(0.199, 60000.14]</td>\n",
       "      <td>(0.299, 60000.24]</td>\n",
       "      <td>(0.399, 60000.34]</td>\n",
       "      <td>(0.499, 60000.44]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 c_0q               c_1q               c_2q  \\\n",
       "0  (-0.001, 59999.94]  (0.099, 60000.04]  (0.199, 60000.14]   \n",
       "1  (-0.001, 59999.94]  (0.099, 60000.04]  (0.199, 60000.14]   \n",
       "\n",
       "                c_3q               c_4q               c_5q  \n",
       "0  (0.299, 60000.24]  (0.399, 60000.34]  (0.499, 60000.44]  \n",
       "1  (0.299, 60000.24]  (0.399, 60000.34]  (0.499, 60000.44]  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from paso.pre.toutil import toContinuousCategory\n",
    "nc = 6\n",
    "nr = 1000000\n",
    "delta = 0.1\n",
    "farr = np.arange(0,(nr*delta*nc),delta, dtype=float).reshape(nr,nc)\n",
    "toDataFrame(farr).toContinuousCategory(drop=True).head(n=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tranform continuous float features into category and leave the original columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-12T14:39:38.917509Z",
     "start_time": "2019-12-12T14:39:38.491086Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-12 09:39:38.578 | INFO     | paso.pre.toutil:toDataFrame:112 - toDataFrame  with column names: Index(['c_0', 'c_1', 'c_2', 'c_3', 'c_4', 'c_5'], dtype='object')\n",
      "2019-12-12 09:39:38.896 | INFO     | paso.pre.toutil:toContinuousCategory:533 - toContinuousCategory features:: Index(['c_0', 'c_1', 'c_2', 'c_3', 'c_4', 'c_5'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c_0</th>\n",
       "      <th>c_1</th>\n",
       "      <th>c_2</th>\n",
       "      <th>c_3</th>\n",
       "      <th>c_4</th>\n",
       "      <th>c_5</th>\n",
       "      <th>c_0fw</th>\n",
       "      <th>c_1fw</th>\n",
       "      <th>c_2fw</th>\n",
       "      <th>c_3fw</th>\n",
       "      <th>c_4fw</th>\n",
       "      <th>c_5fw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>(-599.999, 199999.8]</td>\n",
       "      <td>(-599.899, 199999.9]</td>\n",
       "      <td>(-599.799, 200000.0]</td>\n",
       "      <td>(-599.699, 200000.1]</td>\n",
       "      <td>(-599.599, 200000.2]</td>\n",
       "      <td>(-599.499, 200000.3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>(-599.999, 199999.8]</td>\n",
       "      <td>(-599.899, 199999.9]</td>\n",
       "      <td>(-599.799, 200000.0]</td>\n",
       "      <td>(-599.699, 200000.1]</td>\n",
       "      <td>(-599.599, 200000.2]</td>\n",
       "      <td>(-599.499, 200000.3]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   c_0  c_1  c_2  c_3  c_4  c_5                 c_0fw                 c_1fw  \\\n",
       "0  0.0  0.1  0.2  0.3  0.4  0.5  (-599.999, 199999.8]  (-599.899, 199999.9]   \n",
       "1  0.6  0.7  0.8  0.9  1.0  1.1  (-599.999, 199999.8]  (-599.899, 199999.9]   \n",
       "\n",
       "                  c_2fw                 c_3fw                 c_4fw  \\\n",
       "0  (-599.799, 200000.0]  (-599.699, 200000.1]  (-599.599, 200000.2]   \n",
       "1  (-599.799, 200000.0]  (-599.699, 200000.1]  (-599.599, 200000.2]   \n",
       "\n",
       "                  c_5fw  \n",
       "0  (-599.499, 200000.3]  \n",
       "1  (-599.499, 200000.3]  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toDataFrame(farr).toContinuousCategory(quantile=False,nbin=3,drop=False)\\\n",
    ".head(n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## toutil: toColumnNamesFixedLen\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    def toColumnNamesFixedLen(\n",
    "        oX: pd.DataFrame,\n",
    "        column_length: int = 1,\n",
    "        col_separator: str = \"_\",\n",
    "        inplace: bool = True,\n",
    "        verbose: bool = True,\n",
    "    ) -> pd.DataFrame:\n",
    "    \n",
    "        Parameters:\n",
    "        X: dataset\n",
    "\n",
    "    Keywords:\n",
    "\n",
    "        column_length:  Default: 3\n",
    "            Character length for which to truncate all columns.\n",
    "            The column separator value and number for duplicate\n",
    "            column name does not contribute. Therefore, if all\n",
    "            columns are truncated to 10 characters, the first\n",
    "            distinct column will be 10 characters and the\n",
    "            remaining will be 12 characters (assuming a column\n",
    "            separator of one character).\n",
    "\n",
    "        col_separator: Default: \"_\"\n",
    "            The separator to append plus incremental Int \n",
    "            to create unique column names. Care should be \n",
    "            taken in choosing non-default col_separator \n",
    "            so as to create legal pandas column name.\n",
    "\n",
    "        verbose: Default: True\n",
    "            True: output\n",
    "            False: silent\n",
    "\n",
    "        inplace: Default: True\n",
    "            True: replace 1st argument with resulting dataframe\n",
    "            False:  (boolean)change unplace the dataframe X\n",
    "\n",
    "    Returns: A pandas DataFrame with truncated column lengths.\n",
    "\n",
    "Truncate column name to a specific length.  If\n",
    "column length is shorter, then column length left \n",
    "as is.\n",
    "\n",
    "``toColumnNamesFixedLen`` will truncate all columns to a \n",
    "given length and append a given separator \n",
    "character with the index of duplicate columns, except\n",
    "for the first distinct column name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-12T14:39:38.990167Z",
     "start_time": "2019-12-12T14:39:38.922376Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-12 09:39:38.981 | INFO     | paso.pre.toutil:toDataFrame:112 - toDataFrame  with column names: Index(['long_name', 'another_long_name', 'another_longer_name', 'data'], dtype='object')\n",
      "2019-12-12 09:39:38.982 | INFO     | paso.pre.toutil:toColumnNamesFixedLen:669 - toColumnNamesFixedLen features:: ['long_', 'anoth', 'anoth_1', 'data']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>long_</th>\n",
       "      <th>anoth</th>\n",
       "      <th>anoth_1</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   long_  anoth  anoth_1  data\n",
       "0      1      2        3     4"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toDataFrame([[1,2,3,4]],columns=[\n",
    "     \"long_name\",\n",
    "     \"another_long_name\",\n",
    "     \"another_longer_name\",\n",
    "     \"data\",\n",
    "]).toColumnNamesFixedLen(column_length=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-12T14:39:39.061448Z",
     "start_time": "2019-12-12T14:39:38.992562Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-12 09:39:39.051 | INFO     | paso.pre.toutil:toDataFrame:112 - toDataFrame  with column names: Index(['long_name', 'another_long_name', 'another_longer_name', 'data'], dtype='object')\n",
      "2019-12-12 09:39:39.052 | INFO     | paso.pre.toutil:toColumnNamesFixedLen:669 - toColumnNamesFixedLen features:: ['lo', 'an', 'an=1', 'da']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lo</th>\n",
       "      <th>an</th>\n",
       "      <th>an=1</th>\n",
       "      <th>da</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   lo  an  an=1  da\n",
       "0   1   2     3   4"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toDataFrame([[1,2,3,4]],columns=[\n",
    "     \"long_name\",\n",
    "     \"another_long_name\",\n",
    "     \"another_longer_name\",\n",
    "     \"data\",\n",
    "]).toColumnNamesFixedLen(column_length=2,column_separator= '=')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functional Programming - Creating readable pipelines with chaining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section. I will show a functional programming style in python. This style is also called *chaining* and should be very familiar to those who use **R**.\n",
    "\n",
    "I am going to create one dirty dataset so we can show some of our cleaners in a chain (pipeline)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-12T14:46:58.632959Z",
     "start_time": "2019-12-12T14:46:58.545540Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-12 09:46:58.614 | INFO     | paso.pre.toutil:toDataFrame:112 - toDataFrame  with column names: Index(['c_0', 'c_1', 'c_2', 'c_3', 'c_4', 'c_5'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "arr = np.ndarray(shape=(1000000,6), dtype=int, order='F')\n",
    "dataset = toDataFrame(arr)\n",
    "dataset['date'] = pd.to_datetime('11/30/1956')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-12T15:18:51.149342Z",
     "start_time": "2019-12-12T15:18:49.599219Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-12 10:18:49.817 | INFO     | paso.pre.toutil:toDatetimeComponents:346 - datetime feature component added: date_Year\n",
      "2019-12-12 10:18:49.861 | INFO     | paso.pre.toutil:toDatetimeComponents:346 - datetime feature component added: date_Month\n",
      "2019-12-12 10:18:49.920 | INFO     | paso.pre.toutil:toDatetimeComponents:346 - datetime feature component added: date_Week\n",
      "2019-12-12 10:18:49.962 | INFO     | paso.pre.toutil:toDatetimeComponents:346 - datetime feature component added: date_Day\n",
      "2019-12-12 10:18:50.013 | INFO     | paso.pre.toutil:toDatetimeComponents:346 - datetime feature component added: date_Dayofweek\n",
      "2019-12-12 10:18:50.060 | INFO     | paso.pre.toutil:toDatetimeComponents:346 - datetime feature component added: date_Dayofyear\n",
      "2019-12-12 10:18:50.092 | INFO     | paso.pre.toutil:toDatetimeComponents:346 - datetime feature component added: date_Elapsed\n",
      "2019-12-12 10:18:50.139 | INFO     | paso.pre.toutil:toDatetimeComponents:346 - datetime feature component added: date_Is_month_end\n",
      "2019-12-12 10:18:50.182 | INFO     | paso.pre.toutil:toDatetimeComponents:346 - datetime feature component added: date_Is_month_start\n",
      "2019-12-12 10:18:50.236 | INFO     | paso.pre.toutil:toDatetimeComponents:346 - datetime feature component added: date_Is_quarter_end\n",
      "2019-12-12 10:18:50.280 | INFO     | paso.pre.toutil:toDatetimeComponents:346 - datetime feature component added: date_Is_quarter_start\n",
      "2019-12-12 10:18:50.327 | INFO     | paso.pre.toutil:toDatetimeComponents:346 - datetime feature component added: date_Is_year_end\n",
      "2019-12-12 10:18:50.368 | INFO     | paso.pre.toutil:toDatetimeComponents:346 - datetime feature component added: date_Is_year_start\n",
      "2019-12-12 10:18:50.477 | INFO     | paso.pre.toutil:toDatetimeComponents:351 - datetime feature dropped: date\n",
      "2019-12-12 10:18:50.478 | INFO     | paso.pre.toutil:toColumnNamesFixedLen:669 - toColumnNamesFixedLen features:: ['c_0', 'c_1', 'c_2', 'c_3', 'c_4', 'c_5', 'date_Year', 'date_Month', 'date_Week', 'date_Day', 'date_Dayofwe', 'date_Dayofye', 'date_Elapsed', 'date_Is_mont', 'date_Is_mont_1', 'date_Is_quar', 'date_Is_quar_1', 'date_Is_year', 'date_Is_year_1']\n",
      "2019-12-12 10:18:51.112 | INFO     | paso.pre.toutil:toContinuousCategory:533 - toContinuousCategory features:: Index(['c_0', 'c_1', 'c_2', 'c_3', 'c_4', 'c_5', 'date_Year', 'date_Month',\n",
      "       'date_Week', 'date_Day', 'date_Dayofwe', 'date_Dayofye', 'date_Elapsed',\n",
      "       'date_Is_mont', 'date_Is_mont_1', 'date_Is_quar', 'date_Is_quar_1',\n",
      "       'date_Is_year', 'date_Is_year_1'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c_0</th>\n",
       "      <th>c_1</th>\n",
       "      <th>c_2</th>\n",
       "      <th>c_3</th>\n",
       "      <th>c_4</th>\n",
       "      <th>c_5</th>\n",
       "      <th>date_Year</th>\n",
       "      <th>date_Month</th>\n",
       "      <th>date_Week</th>\n",
       "      <th>date_Day</th>\n",
       "      <th>...</th>\n",
       "      <th>c_2fw</th>\n",
       "      <th>c_3fw</th>\n",
       "      <th>c_4fw</th>\n",
       "      <th>c_5fw</th>\n",
       "      <th>date_Yearfw</th>\n",
       "      <th>date_Monthfw</th>\n",
       "      <th>date_Weekfw</th>\n",
       "      <th>date_Dayfw</th>\n",
       "      <th>date_Dayofwefw</th>\n",
       "      <th>date_Dayofyefw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1956</td>\n",
       "      <td>11</td>\n",
       "      <td>48</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>(-0.0002, 0.0]</td>\n",
       "      <td>(-0.0002, 0.0]</td>\n",
       "      <td>(-0.0002, 0.0]</td>\n",
       "      <td>(-0.0002, 0.0]</td>\n",
       "      <td>(1955.609, 1956.0]</td>\n",
       "      <td>(10.998, 11.0]</td>\n",
       "      <td>(47.99, 48.0]</td>\n",
       "      <td>(29.994, 30.0]</td>\n",
       "      <td>(3.9992, 4.0]</td>\n",
       "      <td>(334.933, 335.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1956</td>\n",
       "      <td>11</td>\n",
       "      <td>48</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>(-0.0002, 0.0]</td>\n",
       "      <td>(-0.0002, 0.0]</td>\n",
       "      <td>(-0.0002, 0.0]</td>\n",
       "      <td>(-0.0002, 0.0]</td>\n",
       "      <td>(1955.609, 1956.0]</td>\n",
       "      <td>(10.998, 11.0]</td>\n",
       "      <td>(47.99, 48.0]</td>\n",
       "      <td>(29.994, 30.0]</td>\n",
       "      <td>(3.9992, 4.0]</td>\n",
       "      <td>(334.933, 335.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1956</td>\n",
       "      <td>11</td>\n",
       "      <td>48</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>(-0.0002, 0.0]</td>\n",
       "      <td>(-0.0002, 0.0]</td>\n",
       "      <td>(-0.0002, 0.0]</td>\n",
       "      <td>(-0.0002, 0.0]</td>\n",
       "      <td>(1955.609, 1956.0]</td>\n",
       "      <td>(10.998, 11.0]</td>\n",
       "      <td>(47.99, 48.0]</td>\n",
       "      <td>(29.994, 30.0]</td>\n",
       "      <td>(3.9992, 4.0]</td>\n",
       "      <td>(334.933, 335.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   c_0  c_1  c_2  c_3  c_4  c_5  date_Year  date_Month  date_Week  date_Day  \\\n",
       "0    0    0    0    0    0    0       1956          11         48        30   \n",
       "1    0    0    0    0    0    0       1956          11         48        30   \n",
       "2    0    0    0    0    0    0       1956          11         48        30   \n",
       "\n",
       "   ...           c_2fw           c_3fw           c_4fw           c_5fw  \\\n",
       "0  ...  (-0.0002, 0.0]  (-0.0002, 0.0]  (-0.0002, 0.0]  (-0.0002, 0.0]   \n",
       "1  ...  (-0.0002, 0.0]  (-0.0002, 0.0]  (-0.0002, 0.0]  (-0.0002, 0.0]   \n",
       "2  ...  (-0.0002, 0.0]  (-0.0002, 0.0]  (-0.0002, 0.0]  (-0.0002, 0.0]   \n",
       "\n",
       "          date_Yearfw    date_Monthfw    date_Weekfw      date_Dayfw  \\\n",
       "0  (1955.609, 1956.0]  (10.998, 11.0]  (47.99, 48.0]  (29.994, 30.0]   \n",
       "1  (1955.609, 1956.0]  (10.998, 11.0]  (47.99, 48.0]  (29.994, 30.0]   \n",
       "2  (1955.609, 1956.0]  (10.998, 11.0]  (47.99, 48.0]  (29.994, 30.0]   \n",
       "\n",
       "   date_Dayofwefw    date_Dayofyefw  \n",
       "0   (3.9992, 4.0]  (334.933, 335.0]  \n",
       "1   (3.9992, 4.0]  (334.933, 335.0]  \n",
       "2   (3.9992, 4.0]  (334.933, 335.0]  \n",
       "\n",
       "[3 rows x 31 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.toDatetimeComponents(inplace=False).toColumnNamesFixedLen(column_length=12).toContinuousCategory(quantile=False,nbin=10,drop=False)\\\n",
    ".head(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice *chaining* is not transitive. The final resulting dataframe will depend on the ordering of chain of functions invocations.\n",
    "\n",
    "For example, the functions in the chain are the same, but the  order of the functions are different. The final result is a different dataframe. In this case, the column names are different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-12T15:29:01.539090Z",
     "start_time": "2019-12-12T15:28:59.971688Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-12 10:29:00.193 | INFO     | paso.pre.toutil:toDatetimeComponents:346 - datetime feature component added: date_Year\n",
      "2019-12-12 10:29:00.237 | INFO     | paso.pre.toutil:toDatetimeComponents:346 - datetime feature component added: date_Month\n",
      "2019-12-12 10:29:00.297 | INFO     | paso.pre.toutil:toDatetimeComponents:346 - datetime feature component added: date_Week\n",
      "2019-12-12 10:29:00.340 | INFO     | paso.pre.toutil:toDatetimeComponents:346 - datetime feature component added: date_Day\n",
      "2019-12-12 10:29:00.391 | INFO     | paso.pre.toutil:toDatetimeComponents:346 - datetime feature component added: date_Dayofweek\n",
      "2019-12-12 10:29:00.437 | INFO     | paso.pre.toutil:toDatetimeComponents:346 - datetime feature component added: date_Dayofyear\n",
      "2019-12-12 10:29:00.467 | INFO     | paso.pre.toutil:toDatetimeComponents:346 - datetime feature component added: date_Elapsed\n",
      "2019-12-12 10:29:00.513 | INFO     | paso.pre.toutil:toDatetimeComponents:346 - datetime feature component added: date_Is_month_end\n",
      "2019-12-12 10:29:00.556 | INFO     | paso.pre.toutil:toDatetimeComponents:346 - datetime feature component added: date_Is_month_start\n",
      "2019-12-12 10:29:00.606 | INFO     | paso.pre.toutil:toDatetimeComponents:346 - datetime feature component added: date_Is_quarter_end\n",
      "2019-12-12 10:29:00.651 | INFO     | paso.pre.toutil:toDatetimeComponents:346 - datetime feature component added: date_Is_quarter_start\n",
      "2019-12-12 10:29:00.697 | INFO     | paso.pre.toutil:toDatetimeComponents:346 - datetime feature component added: date_Is_year_end\n",
      "2019-12-12 10:29:00.741 | INFO     | paso.pre.toutil:toDatetimeComponents:346 - datetime feature component added: date_Is_year_start\n",
      "2019-12-12 10:29:00.857 | INFO     | paso.pre.toutil:toDatetimeComponents:351 - datetime feature dropped: date\n",
      "2019-12-12 10:29:01.500 | INFO     | paso.pre.toutil:toContinuousCategory:533 - toContinuousCategory features:: Index(['c_0', 'c_1', 'c_2', 'c_3', 'c_4', 'c_5', 'date_Year', 'date_Month',\n",
      "       'date_Week', 'date_Day', 'date_Dayofweek', 'date_Dayofyear',\n",
      "       'date_Elapsed', 'date_Is_month_end', 'date_Is_month_start',\n",
      "       'date_Is_quarter_end', 'date_Is_quarter_start', 'date_Is_year_end',\n",
      "       'date_Is_year_start'],\n",
      "      dtype='object')\n",
      "2019-12-12 10:29:01.502 | INFO     | paso.pre.toutil:toColumnNamesFixedLen:669 - toColumnNamesFixedLen features:: ['c_0', 'c_1', 'c_2', 'c_3', 'c_4', 'c_5', 'date_Year', 'date_Month', 'date_Week', 'date_Day', 'date_Dayofwe', 'date_Dayofye', 'date_Elapsed', 'date_Is_mont', 'date_Is_mont_1', 'date_Is_quar', 'date_Is_quar_1', 'date_Is_year', 'date_Is_year_1', 'c_0fw', 'c_1fw', 'c_2fw', 'c_3fw', 'c_4fw', 'c_5fw', 'date_Yearfw', 'date_Monthfw', 'date_Weekfw', 'date_Dayfw', 'date_Dayofwe_1', 'date_Dayofye_1']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c_0</th>\n",
       "      <th>c_1</th>\n",
       "      <th>c_2</th>\n",
       "      <th>c_3</th>\n",
       "      <th>c_4</th>\n",
       "      <th>c_5</th>\n",
       "      <th>date_Year</th>\n",
       "      <th>date_Month</th>\n",
       "      <th>date_Week</th>\n",
       "      <th>date_Day</th>\n",
       "      <th>...</th>\n",
       "      <th>c_2fw</th>\n",
       "      <th>c_3fw</th>\n",
       "      <th>c_4fw</th>\n",
       "      <th>c_5fw</th>\n",
       "      <th>date_Yearfw</th>\n",
       "      <th>date_Monthfw</th>\n",
       "      <th>date_Weekfw</th>\n",
       "      <th>date_Dayfw</th>\n",
       "      <th>date_Dayofwe_1</th>\n",
       "      <th>date_Dayofye_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1956</td>\n",
       "      <td>11</td>\n",
       "      <td>48</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>(-0.0002, 0.0]</td>\n",
       "      <td>(-0.0002, 0.0]</td>\n",
       "      <td>(-0.0002, 0.0]</td>\n",
       "      <td>(-0.0002, 0.0]</td>\n",
       "      <td>(1955.609, 1956.0]</td>\n",
       "      <td>(10.998, 11.0]</td>\n",
       "      <td>(47.99, 48.0]</td>\n",
       "      <td>(29.994, 30.0]</td>\n",
       "      <td>(3.9992, 4.0]</td>\n",
       "      <td>(334.933, 335.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1956</td>\n",
       "      <td>11</td>\n",
       "      <td>48</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>(-0.0002, 0.0]</td>\n",
       "      <td>(-0.0002, 0.0]</td>\n",
       "      <td>(-0.0002, 0.0]</td>\n",
       "      <td>(-0.0002, 0.0]</td>\n",
       "      <td>(1955.609, 1956.0]</td>\n",
       "      <td>(10.998, 11.0]</td>\n",
       "      <td>(47.99, 48.0]</td>\n",
       "      <td>(29.994, 30.0]</td>\n",
       "      <td>(3.9992, 4.0]</td>\n",
       "      <td>(334.933, 335.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1956</td>\n",
       "      <td>11</td>\n",
       "      <td>48</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>(-0.0002, 0.0]</td>\n",
       "      <td>(-0.0002, 0.0]</td>\n",
       "      <td>(-0.0002, 0.0]</td>\n",
       "      <td>(-0.0002, 0.0]</td>\n",
       "      <td>(1955.609, 1956.0]</td>\n",
       "      <td>(10.998, 11.0]</td>\n",
       "      <td>(47.99, 48.0]</td>\n",
       "      <td>(29.994, 30.0]</td>\n",
       "      <td>(3.9992, 4.0]</td>\n",
       "      <td>(334.933, 335.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   c_0  c_1  c_2  c_3  c_4  c_5  date_Year  date_Month  date_Week  date_Day  \\\n",
       "0    0    0    0    0    0    0       1956          11         48        30   \n",
       "1    0    0    0    0    0    0       1956          11         48        30   \n",
       "2    0    0    0    0    0    0       1956          11         48        30   \n",
       "\n",
       "   ...           c_2fw           c_3fw           c_4fw           c_5fw  \\\n",
       "0  ...  (-0.0002, 0.0]  (-0.0002, 0.0]  (-0.0002, 0.0]  (-0.0002, 0.0]   \n",
       "1  ...  (-0.0002, 0.0]  (-0.0002, 0.0]  (-0.0002, 0.0]  (-0.0002, 0.0]   \n",
       "2  ...  (-0.0002, 0.0]  (-0.0002, 0.0]  (-0.0002, 0.0]  (-0.0002, 0.0]   \n",
       "\n",
       "          date_Yearfw    date_Monthfw    date_Weekfw      date_Dayfw  \\\n",
       "0  (1955.609, 1956.0]  (10.998, 11.0]  (47.99, 48.0]  (29.994, 30.0]   \n",
       "1  (1955.609, 1956.0]  (10.998, 11.0]  (47.99, 48.0]  (29.994, 30.0]   \n",
       "2  (1955.609, 1956.0]  (10.998, 11.0]  (47.99, 48.0]  (29.994, 30.0]   \n",
       "\n",
       "   date_Dayofwe_1    date_Dayofye_1  \n",
       "0   (3.9992, 4.0]  (334.933, 335.0]  \n",
       "1   (3.9992, 4.0]  (334.933, 335.0]  \n",
       "2   (3.9992, 4.0]  (334.933, 335.0]  \n",
       "\n",
       "[3 rows x 31 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.toDatetimeComponents(inplace=False)\\\n",
    ".toContinuousCategory(quantile=False,nbin=10,drop=False)\\\n",
    ".toColumnNamesFixedLen(column_length=12)\\\n",
    ".head(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting with Python 3.6 (PEP 484), type hints were introduced. Type hints (note: not strong type checking) make it possible to also do static type checking of Python code with downstream tools.\n",
    "\n",
    "Using type hints, the ``toutil`` function call signatures are summarized:\n",
    "\n",
    "    # 1\n",
    "    paso.pre.toutil.toDataFrame(\n",
    "            X: pd.DataFrame,\n",
    "            columns: List = None, \n",
    "            inplace: bool = True, \n",
    "            verbose: bool = True) -> pd.DataFrame:\n",
    "    #2\n",
    "    paso.pre.toutil.toCategory(\n",
    "        X: pd.DataFrame,\n",
    "        bool_: bool = True,\n",
    "        int_: bool = True,\n",
    "        object_: str = True,\n",
    "        inplace: bool = True,\n",
    "        verbose: bool = True) -> pd.DataFrame:\n",
    "\n",
    "    #3\n",
    "    paso.pre.toutil.datetimeComponents():\n",
    "\n",
    "    #4\n",
    "     paso.pre.toutil.toDatetimeComponents(\n",
    "        oX: pd.DataFrame,\n",
    "        drop: bool = True,\n",
    "        components: list = [],\n",
    "        prefix: bool = True,\n",
    "        inplace: bool = True,\n",
    "        verbose: bool = True) -> pd.DataFrame:\n",
    "\n",
    "    #5\n",
    "    paso.pre.toutil.def toColumnNamesFixedLen(\n",
    "        X: pd.DataFrame,\n",
    "        column_length: int = 1,\n",
    "        col_separator: str = \"_\",\n",
    "        inplace: bool = True,\n",
    "        verbose: bool = True) -> pd.DataFrame:\n",
    "\n",
    "The code for this lesson is given in [here](https://github.com/bcottman/paso/blob/master/lessons/) and [here](https://github.com/bcottman/paso/blob/master/paso/pre/toutil.py) files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other lessons on **paso** are:\n",
    "\n",
    "[**paso**'s Offering of Logging and Parameter Services for your Python Project](https://github.com/bcottman/paso/blob/master/lessons/lesson_1.ipynb)\n",
    "\n",
    "[Part 1: Balancing and Augmenting Structured Data](https://medium.com/@dr.bruce.cottman/part-1-balancing-and-augmenting-structured-data-4ade0df38662)\n",
    "\n",
    "[Part 1 - Uncommon Data Cleaners for your Real-World Machine Learning Projects](https://github.com/bcottman/paso/blob/master/lessons/lesson-2.ipynb).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the future, we will cover **paso** in more depth with the following lessons:\n",
    "\n",
    "- Chaining an entire Machine Leaning Pipeline.\n",
    "- Part 2: Yet more (and better) methods for Balancing and Augmenting Structured Data.\n",
    "- Part 1: Different encoding methods for categorical features.\n",
    "- Part 2: Deep learning encoding for categorical features.\n",
    "\n",
    "If you have a service or feature or see a bug, then leave the **paso** project a [note](https://github.com/bcottman/paso/issues)."
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "155.81521606445312px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
